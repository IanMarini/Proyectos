# -*- coding: utf-8 -*-
"""Proyecto Cancer de Mama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1foSwpBzfUYYNtFuBfloTFnQKkvGkPeHn
"""

!pip install gTTS

from gtts import gTTS
from IPython.display import Audio
tts = gTTS('Este conjunto de datos se basa en información recopilada por el Programa SEER (Surveillance, Epidemiology, and End Results) del Instituto Nacional del Cáncer (NCI), actualizado en noviembre de 2017. El SEER es un programa de vigilancia del cáncer que recopila datos a nivel nacional para proporcionar estadísticas detalladas sobre diversos tipos de cáncer.El enfoque de este conjunto de datos se centra específicamente en pacientes femeninas diagnosticadas con carcinoma lobular y de conducto infiltrante de cáncer de mama. La recopilación de datos abarca el período comprendido entre los años 2006 y 2010.Se aplicaron criterios de exclusión rigurosos para garantizar la calidad de la información. Se eliminaron pacientes con datos insuficientes, como el tamaño del tumor desconocido, nodos linfáticos regionales no examinados y nodos linfáticos regionales con resultados positivos, así como aquellos cuya supervivencia fue inferior a 1 mes. Como resultado de estos criterios, el conjunto de datos final incluye un total de 4.024 pacientes.',lang='es')
tts.save('1.wav')
sound_file = '1.wav'
Audio(sound_file, autoplay=True)

"""# Proyecto Cáncer de Mama.

### **Introducción.**
El conjunto de datos de cáncer de mama es una valiosa fuente de información recopilada por el Programa SEER (Surveillance, Epidemiology, and End Results) del Instituto Nacional del Cáncer (NCI). Este programa es una iniciativa de vigilancia del cáncer a nivel nacional que proporciona estadísticas detalladas sobre diversos tipos de cáncer, facilitando la investigación y el análisis en el campo de la oncología.

**Enfoque y Cobertura**

Este conjunto de datos se centra específicamente en pacientes femeninas diagnosticadas con carcinoma lobular y de conducto infiltrante de cáncer de mama. La información abarca el período comprendido entre los años 2006 y 2010, ofreciendo un panorama exhaustivo de estos tipos de cáncer durante estos años.

**Criterios de Exclusión**

Para asegurar la calidad y la precisión de la información, se aplicaron criterios de exclusión rigurosos. Los pacientes fueron eliminados del conjunto de datos si presentaban:

* Tamaño del tumor desconocido.
* Nodos linfáticos regionales no examinados.
* Resultados positivos en nodos linfáticos regionales.
* Supervivencia inferior a 1 mes.

**Conjunto de Datos Final**

Después de aplicar los criterios de exclusión, el conjunto de datos final incluye información detallada de un total de 4,024 pacientes. Estos datos proporcionan una base sólida para realizar análisis estadísticos y estudios epidemiológicos sobre el cáncer de mama, permitiendo identificar patrones, tendencias y factores clave relacionados con la incidencia y la supervivencia de este tipo de cáncer.

**Objetivo de la Presentación**

El objetivo de esta presentación es brindar una visión general del conjunto de datos sobre cáncer de mama, destacando su importancia y las oportunidades que ofrece para la investigación. A través de este análisis, se espera contribuir a un mejor entendimiento del cáncer de mama y apoyar el desarrollo de estrategias más efectivas para su diagnóstico, tratamiento y prevención.

Presentación: Introducción al Conjunto de Datos sobre Cáncer de Mama.

### **Descripción.**
El conjunto de datos sobre cáncer de mama del Programa SEER es una colección de información detallada y precisa sobre pacientes femeninas diagnosticadas con carcinoma lobular y de conducto infiltrante de cáncer de mama. La recopilación de datos se realizó entre los años 2006 y 2010 y se centró en proporcionar una imagen clara y comprensiva de estos tipos de cáncer.

**Características**
* Fuente: Programa SEER (Surveillance, Epidemiology, and End Results) del Instituto Nacional del Cáncer (NCI).
* Cobertura Temporal: 2006-2010.
* Pacientes: Mujeres diagnosticadas con carcinoma lobular y de conducto infiltrante.
* Criterios de Exclusión: Pacientes con tamaño de tumor desconocido, nodos linfáticos regionales no examinados, resultados positivos en nodos linfáticos regionales y supervivencia inferior a 1 mes.
* Total de Pacientes: 4,024.

**Importancia**
Este conjunto de datos es crucial para la investigación en oncología, ya que ofrece:

* Estadísticas Detalladas: Proporciona una base sólida de datos que permite realizar análisis estadísticos detallados sobre el cáncer de mama.
* Investigación Epidemiológica: Facilita estudios epidemiológicos que pueden identificar patrones y tendencias en la incidencia y supervivencia del cáncer de mama.
* Desarrollo de Estrategias: Apoya el desarrollo de estrategias más efectivas para el diagnóstico, tratamiento y prevención del cáncer de mama.

**Aplicaciones**
* Análisis Estadístico: Permite realizar análisis detallados para identificar factores de riesgo y patrones en la incidencia del cáncer de mama.
* Investigación Clínica: Ayuda en el desarrollo de nuevos métodos de diagnóstico y tratamiento.
* Políticas de Salud: Informa la creación de políticas de salud pública y programas de prevención.

### **Variables.**

`Age`: Edad de la paciente.

`Race`: Raza de la paciente.

`Marital Status`: Estado civil de la paciente.

`T Stage`: Estado T del tumor (Tamaño del tumor primario).

`N Stage`: Estado N del tumor (Afectación de los ganglios linfáticos regionales).

`6th Stage`: Estado general del cáncer basado en la clasificación de la sexta edición del sistema TNM.

`Differentiate`: Grado de diferenciación del tumor.

`Grade`: Grado del tumor.

`A Stage`: Etapa del cáncer.

`Tumor Size`: Tamaño del tumor.

`Estrogen Status`: Estado del receptor de estrógeno.

`Progesterone Status`: Estado del receptor de progesterona.

`Regional Node Examined`: Número de nodos linfáticos regionales examinados.

`Regional Node Positive`: Número de nodos linfáticos regionales con resultados positivos.

`Survival Months`: Meses de supervivencia.

`Status`: Estado actual de la paciente (Viva / Fallecida).

> Estos atributos proporcionan información valiosa para analizar y comprender mejor el cáncer de mama, sus características clínicas y los resultados de supervivencia en el grupo de pacientes seleccionado.

### Librerias.
"""

# Commented out IPython magic to ensure Python compatibility.
# %config IPCompleter.greedy=True

# Importación de librerías necesarias

# Tratamiento de datos
# ==============================================================================
import numpy as np                    # Importar Numpy
import pandas as pd                   # Importar Pandas
import scipy as sp                    # Importar SciPy
from prettytable import PrettyTable

# Gráficos
# ==============================================================================
import matplotlib as mpl              # Importar Matplotlib
import matplotlib.pyplot as plt       # Módulo Pyplot de Matplotlib
import seaborn as sns                 # Importar Seaborn
import plotly.express as px           # Importar Plotly Express

mpl.style.use('bmh')                  # Establecer un estilo para Matplotlib

# Preprocesado y modelado
# ==============================================================================
from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
import statsmodels.api as sm
from sklearn.utils import resample, shuffle
from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, train_test_split, learning_curve
from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel

# Modelos de Clasificación
# ==============================================================================
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
import xgboost

# Métricas
# ==============================================================================
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error
from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_curve

# Configuración de warnings
# ==============================================================================
import warnings
warnings.filterwarnings('ignore')

# Otras importaciones
# ==============================================================================
import xlrd
from matplotlib.ticker import PercentFormatter

# Configuración adicional
# ==============================================================================
sns.set()  # Configuración de Seaborn

"""#### Cargar la Base de Datos por medio de Google Drive.

* Montar Google Drive
* Cargar el archivo
"""

from google.colab import files

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv ("/content/drive/MyDrive/Colab Notebooks/1. Breast_Cancer/Breast_Cancer.csv")
df.shape

"""## DataSet Cancer de Mama.

**Previsualización y Exploración Inicial del Conjunto de Datos**

Antes de realizar un análisis detallado y construir modelos predictivos, es esencial llevar a cabo una previsualización del conjunto de datos. Esta etapa nos permitirá comprender mejor la estructura y la calidad de los datos, asegurándonos de que están preparados para un análisis más profundo.

**Objetivo de la Previsualización**

El propósito de esta previsualización es proporcionar una visión general del conjunto de datos, lo que nos ayudará a:

1. Comprender la Estructura de los Datos:

  * Familiarizarnos con las características disponibles y su naturaleza (numérica, categórica, etc.).
  * Identificar la cantidad de datos presentes y la distribución de las variables clave.

2. Evaluar la Calidad de los Datos:

  * Detectar la presencia de valores faltantes o inconsistentes.
  * Identificar posibles valores atípicos que podrían influir en el análisis.

3. Guiar el Análisis Posterior:

  * Establecer una base para los análisis descriptivos y exploratorios que seguirán.
  * Informar sobre cualquier limpieza o transformación de datos que pueda ser necesaria.

**Previsualización de los Datos**

A continuación, se mostrarán datos del conjunto de datos sobre cáncer de mama para llevar a cabo una previsualización inicial. Esta visualización nos permitirá tener una primera impresión sobre la distribución de las variables y la integridad de los datos:
"""

df.head (10)

df.describe

df.columns

df.info

df.dtypes

df.isnull().sum()

"""**Conclusión**

Esta previsualización inicial nos proporciona una comprensión fundamental de nuestro conjunto de datos sobre cáncer de mama. En las siguientes secciones, utilizaremos estos datos para realizar análisis más detallados y desarrollar modelos predictivos que nos permitan extraer insights valiosos y mejorar nuestro entendimiento de esta enfermedad.

### Estrucurando un Proyecto de DS PARTE 1

**Preguntas de Interés:**

* ¿Existe alguna relación entre la edad de las pacientes y la etapa del cáncer de mama en el momento del diagnóstico?

* ¿Cómo afecta el tamaño del tumor al estadio del cáncer de mama?

* ¿Hay diferencias en la supervivencia entre pacientes con carcinoma lobular y pacientes con carcinoma de conducto infiltrante?

* ¿La raza de las pacientes influye en la etapa del cáncer o en la supervivencia?

* ¿Existe una asociación entre el estado marital y la etapa del cáncer de mama?

* ¿Cómo se relacionan las variables de diferenciación y grado del tumor?

* ¿Hay alguna correlación entre el tamaño del tumor y el número de nodos linfáticos regionales examinados?

* ¿La presencia de receptores de estrógeno o progesterona está relacionada con la supervivencia?

Muestra la distribución de la edad de las pacientes diagnosticadas con cáncer de mama. Utiliza un histograma con un estimador de densidad de Kernel (KDE) para suavizar la curva de distribución.

* `Interpretación`: La mayoría de las pacientes tienen una edad comprendida entre 50 y 70 años. Esto sugiere que el cáncer de mama es más común en este grupo de edad.
* `Importancia`: Comprender la distribución de la edad es crucial para identificar los grupos de riesgo y desarrollar estrategias de detección temprana dirigidas a estos grupos específicos.
"""

plt.figure(figsize=(10, 6))
sns.histplot(df['Age'], bins=30, kde=True, color='deeppink')
plt.title('Distribución de la Edad de las Pacientes', fontsize=15, fontweight='bold')
plt.xlabel('Edad', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)
plt.show()

"""Muestra la distribución del tamaño del tumor en las pacientes diagnosticadas con cáncer de mama. Al igual que el gráfico anterior, utiliza un histograma y un KDE.

* `Interpretación`: Los tamaños de los tumores parecen variar ampliamente, con un pico alrededor de los 20-30 mm.
* `Importancia`: Analizar el tamaño del tumor puede ayudar a comprender la progresión de la enfermedad y su detección en diferentes etapas.
"""

plt.figure(figsize=(10, 6))
sns.histplot(df['Tumor Size'], bins=30, kde=True, color='mediumvioletred')
plt.title('Distribución del Tamaño del Tumor', fontsize=15, fontweight='bold')
plt.xlabel('Tamaño del Tumor', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)
plt.show()

"""Muestra la relación entre la edad de las pacientes y la etapa del tumor (T Stage).

* `Interpretación`: Cada caja representa la distribución de edades dentro de cada etapa del tumor. Las líneas horizontales dentro de las cajas indican la mediana de edad para cada etapa.
* `Importancia`: Este análisis puede revelar si ciertos grupos de edad son más propensos a ser diagnosticados en etapas avanzadas del cáncer, lo que puede influir en las estrategias de prevención y detección.
"""

plt.figure(figsize=(12, 8))
sns.boxplot(x='T Stage ', y='Age', data=df, palette='pink_r')
plt.title('Relación entre Edad y Etapa del Cáncer', fontsize=15, fontweight='bold')
plt.xlabel('Etapa T del Tumor', fontsize=12)
plt.ylabel('Edad', fontsize=12)
plt.show()

"""Ilustra la relación entre el tamaño del tumor y la etapa del cáncer.

* `Interpretación`: Se espera ver un aumento en el tamaño del tumor con el avance de la etapa T, lo que indicaría la progresión del cáncer.
* `Importancia`: Identificar esta relación es vital para entender cómo se desarrolla el cáncer de mama y puede ayudar a mejorar las guías clínicas para el manejo del cáncer en diferentes etapas.
"""

plt.figure(figsize=(12, 8))
sns.boxplot(x='T Stage ', y='Tumor Size', data=df, palette='RdPu')
plt.title('Relación entre Tamaño del Tumor y Etapa del Cáncer', fontsize=15, fontweight='bold')
plt.xlabel('Etapa T del Tumor', fontsize=12)
plt.ylabel('Tamaño del Tumor', fontsize=12)
plt.show()

"""Muestra la supervivencia (en meses) por estado actual de la paciente (viva o fallecida), diferenciando por la sexta etapa del sistema TNM.

* `Interpretación`: Las cajas indican la distribución de los meses de supervivencia para cada grupo. La comparación entre diferentes etapas del cáncer (hue) permite observar cómo la etapa afecta la supervivencia.
* `Importancia`: Comprender la relación entre la etapa del cáncer y la supervivencia puede ayudar en la planificación de tratamientos y pronósticos.
"""

plt.figure(figsize=(12, 8))
sns.boxplot(x='Status', y='Survival Months', hue='6th Stage', data=df, palette='pink')
plt.title('Supervivencia por Tipo de Carcinoma', fontsize=15, fontweight='bold')
plt.xlabel('Estado Actual', fontsize=12)
plt.ylabel('Meses de Supervivencia', fontsize=12)
plt.show()

"""Muestra la relación entre el estado marital de las pacientes y la etapa del tumor.

* `Interpretación`: Las barras apiladas permiten observar si hay una tendencia entre diferentes estados maritales y la etapa del cáncer en el momento del diagnóstico.
* `Importancia`: Investigar esta relación puede revelar cómo el estado marital influye en el diagnóstico y el manejo del cáncer, lo que puede tener implicaciones para el apoyo social y la intervención médica.
"""

# Diccionario para mapear las etiquetas al español
marital_status_mapping = {
    'Married': 'Casada',
    'Divorced': 'Divorciada',
    'Single': 'Soltera',
    'Widowed': 'Viuda',
    'Separated': 'Separada'
}

# Aplicar el mapeo a la columna 'Marital Status'
df['Marital Status'] = df['Marital Status'].map(marital_status_mapping)

# Graficar la relación entre Estado Marital y Etapa del Cáncer
plt.figure(figsize=(12, 8))
sns.countplot(x='Marital Status', hue='T Stage ', data=df, palette='pink')
plt.title('Relación entre Estado Marital y Etapa del Cáncer', fontsize=15, fontweight='bold')
plt.xlabel('Estado Marital', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)
plt.legend(title='Etapa del Tumor', loc='upper right')
plt.show()

"""Muestra la relación entre el tamaño del tumor y el número de nodos linfáticos regionales examinados.

* `Interpretación`: Cada punto representa una paciente, permitiendo observar si hay una correlación directa entre el tamaño del tumor y la cantidad de nodos examinados.
* `Importancia`: Una correlación fuerte puede indicar que los tumores más grandes requieren un examen más exhaustivo de los nodos linfáticos, lo cual es crucial para la estadificación y el tratamiento del cáncer.
"""

plt.figure(figsize=(10, 6))
sns.scatterplot(x='Tumor Size', y='Regional Node Examined', data=df, color='deeppink')
plt.title('Correlación entre Tamaño del Tumor y Nodos Linfáticos Examinados', fontsize=15, fontweight='bold')
plt.xlabel('Tamaño del Tumor', fontsize=12)
plt.ylabel('Nodos Linfáticos Examinados', fontsize=12)
plt.show()

"""Muestra la relación entre el estado del receptor de estrógeno y la supervivencia, diferenciando por el estado actual de la paciente (viva o fallecida).

* `Interpretación`: Las cajas muestran la distribución de los meses de supervivencia para pacientes con diferentes estados del receptor de estrógeno. La comparación entre los estados actuales permite ver cómo estos afectan la supervivencia.
* `Importancia`: Entender esta relación es vital para determinar el pronóstico y la efectividad de las terapias hormonales en el tratamiento del cáncer de mama.
"""

plt.figure(figsize=(12, 8))
sns.boxplot(x='Estrogen Status', y='Survival Months', hue='Status', data=df, palette='RdPu')
plt.title('Estado de Receptores de Estrógeno y Supervivencia', fontsize=15, fontweight='bold')
plt.xlabel('Estado del Receptor de Estrógeno', fontsize=12)
plt.ylabel('Meses de Supervivencia', fontsize=12)
plt.show()

"""**Resumen Numérico y Análisis de los Gráficos**

---

**Distribución por Raza de las Pacientes:**

Se realizó un conteo de la frecuencia de cada raza en el conjunto de datos.
Se observó que había un gran número de pacientes clasificadas como 'Desconocido' en la categoría de raza.

**Relación entre Estado Marital y Etapa del Cáncer:**

Se graficó la relación entre el estado marital y la etapa del tumor ('T Stage').
Se mapearon las etiquetas del estado marital al español ('Casada', 'Divorciada', 'Soltera', 'Viuda', 'Separada').
La visualización mostró cómo se distribuyen las diferentes etapas del tumor entre las diferentes categorías de estado marital.

---

**Conclusiones y Observaciones**

---

**Relación entre Estado Marital y Etapa del Cáncer:**

Se observó una distribución variada de las etapas del tumor entre los diferentes estados maritales.
Por ejemplo, podría notarse una mayor prevalencia de ciertas etapas del tumor entre pacientes divorciadas o viudas en comparación con las casadas o solteras.

---

**Recomendaciones**

---

**Validación de Datos:**

Es importante validar la precisión y completitud de los datos de raza, dado el alto número de entradas clasificadas como 'Desconocido'.
Esto podría requerir revisar el proceso de recopilación de datos o explorar métodos alternativos para obtener información más precisa.

**Análisis Adicional:**

Para un análisis más profundo, sería beneficioso explorar otras variables y realizar correlaciones entre diferentes características del conjunto de datos.
"""

# Resúmenes numéricos
# Conteo de la frecuencia de cada raza
race_counts = df['Race'].value_counts()

# Mostrar el conteo de cada raza
print("Distribución por Raza de las Pacientes:")
print(race_counts)
print()
print(" ")
print("Resumen numérico de Edades:")
print(df['Age'].describe())
print(" ")
# 2. Relación entre Estado Marital y Etapa del Cáncer
# Mapeo de etiquetas al español
marital_status_mapping = {
    'Married': 'Casada',
    'Divorced': 'Divorciada',
    'Single': 'Soltera',
    'Widowed': 'Viuda',
    'Separated': 'Separada'
}

# Aplicar el mapeo a la columna 'Marital Status'
df['Marital Status'] = df['Marital Status'].map(marital_status_mapping)

# Graficar la relación entre Estado Marital y Etapa del Cáncer
# Por ejemplo, contar las ocurrencias de cada estado marital para cada etapa del tumor
marital_stage_counts = df.groupby(['Marital Status', 'T Stage ']).size().unstack()

# Mostrar el resumen de la relación entre Estado Marital y Etapa del Cáncer
print("Relación entre Estado Marital y Etapa del Cáncer:")
print(marital_stage_counts)
print()

print("\nResumen numérico del Tamaño del Tumor:")
print(df['Tumor Size'].describe())

print("\nResumen numérico de la Supervivencia:")
print(df['Survival Months'].describe())
print(" ")

# Resumen adicional o análisis específico que desees agregar...
# Conclusiones y observaciones
print("Conclusiones:")
print("- Se observó una distribución variada de las etapas del tumor entre diferentes estados maritales.")
print("- La mayoría de las pacientes están clasificadas como 'Desconocido' en cuanto a su raza.")
print("- Recomendación: Validar la precisión y completitud de los datos de raza.")

"""### Estrucurando un Proyecto de DS PARTE 2

**Abstracto con motivación y audiencia:**

El estudio se enfoca en un conjunto de datos del Programa SEER del Instituto Nacional del Cáncer sobre pacientes femeninas diagnosticadas con carcinoma lobular y de conducto infiltrante de cáncer de mama entre 2006 y 2010.

El objetivo es proporcionar insights valiosos para mejorar la comprensión de factores relacionados con la supervivencia en este grupo de pacientes.

 La audiencia principal son profesionales de la salud, investigadores y responsables de la toma de decisiones en el ámbito oncológico.

**Preguntas/Hipótesis que queremos resolver mediante el análisis de datos:**

* ¿Cuáles son los factores que más influyen en la supervivencia de las pacientes con cáncer de mama?

* ¿Existen patrones o tendencias en la edad, etapa del tumor, tamaño del tumor, estado hormonal, entre otros, que puedan proporcionar información valiosa?

* ¿Hay alguna relación entre el estado civil y la supervivencia de las pacientes?

**Análisis Exploratorio de Datos (EDA):**

Se han realizado visualizaciones y resúmenes numéricos para explorar diversas variables clave. Entre ellas se encuentran la distribución de edades, el tamaño del tumor, la relación entre la edad y las etapas del cáncer, la distribución de la supervivencia, la relación entre el tamaño del tumor y los nodos linfáticos examinados, la comparación de la supervivencia por tipo de diferenciación celular y la comparación de etapas por raza.

Además, se ha incluido una matriz de correlación para evaluar las relaciones entre las variables.

**Recomendaciones basadas en los insights observados:**

* Se podría considerar un enfoque de tratamiento personalizado, teniendo en cuenta la edad y el tipo de diferenciación celular.

* Dada la relación entre el tamaño del tumor y la supervivencia, se podrían explorar estrategias de detección temprana y tratamientos específicos para tumores de ciertos tamaños.

* La relación entre el tamaño del tumor y la cantidad de nodos linfáticos examinados sugiere la importancia de una evaluación exhaustiva de los nodos en pacientes con tumores más grandes.

* La comparación de etapas por raza podría motivar investigaciones adicionales sobre disparidades en el diagnóstico y tratamiento.

**Avances en los apartados:**

1. Definición del Objetivo:

El objetivo principal de este análisis es comprender y predecir la supervivencia de pacientes femeninas diagnosticadas con carcinoma lobular y de conducto infiltrante de cáncer de mama.

La variable objetivo es "Survival Months", que representa la cantidad de meses que una paciente ha sobrevivido después del diagnóstico.

La predicción de la supervivencia es esencial para ofrecer información valiosa a profesionales de la salud, investigadores y pacientes, permitiendo una mejor planificación del tratamiento y la toma de decisiones.

2. Contexto Comercial:

En el ámbito comercial, este análisis puede proporcionar información valiosa para las compañías farmacéuticas, hospitales y profesionales de la salud.

La capacidad de prever la supervivencia de pacientes con cáncer de mama puede influir en el desarrollo de tratamientos más efectivos y personalizados, así como en la asignación eficiente de recursos en el sistema de salud.

3. Problema Comercial:

El problema principal es la necesidad de identificar factores que afectan la supervivencia de pacientes con cáncer de mama y desarrollar un modelo predictivo preciso.

Esto permitirá a los profesionales de la salud tomar decisiones informadas sobre tratamientos y proporcionar a los pacientes una comprensión más clara de su pronóstico.

4. Contexto Analítico:

En el contexto analítico, se busca utilizar técnicas de aprendizaje automático y análisis estadístico para desarrollar un modelo predictivo.

Se explorarán las relaciones entre las diversas variables del conjunto de datos y la variable objetivo ("Survival Months") para identificar patrones y tendencias.

La evaluación del rendimiento del modelo permitirá determinar su utilidad en la predicción de la supervivencia de pacientes con cáncer de mama.

5. Exploración de Datos (EDA):

La fase de exploración de datos implica analizar en detalle las variables proporcionadas en el conjunto de datos.

Esto incluirá estadísticas descriptivas, visualizaciones y la identificación de posibles correlaciones entre las variables.

Se buscarán patrones y anomalías que puedan influir en la supervivencia de los pacientes.

La EDA será crucial para tomar decisiones informadas sobre la selección de características y la construcción del modelo predictivo.

**Distribución de Meses de Supervivencia**

* Descripción: Este gráfico de línea muestra cómo se distribuyen los meses de supervivencia entre los pacientes con carcinoma lobular y de conducto infiltrante de cáncer de mama.

**Interpretación:**

1. Eje X (Meses de Supervivencia): Representa los diferentes períodos de supervivencia en meses.

2. Eje Y (Número de Pacientes): Indica cuántos pacientes tienen esa cantidad específica de meses de supervivencia.

3. Patrones: La forma de la línea revela la distribución general de la supervivencia en el conjunto de datos.

Por ejemplo, picos altos pueden indicar períodos comunes de supervivencia, mientras que áreas más planas podrían indicar variabilidad en la supervivencia.
"""

# Tabla de distribución de Meses de Supervivencia
survival_months_distribution = df['Survival Months'].value_counts().reset_index()
survival_months_distribution.columns = ['Meses de Supervivencia', 'Frecuencia']
print(survival_months_distribution)

# Calcular la distribución de meses de supervivencia
supervivencia_distribucion = df['Survival Months'].value_counts().sort_index()

# Configuración de la figura
plt.figure(figsize=(12, 8))

# Gráfico de línea con puntos para mostrar la distribución
plt.plot(supervivencia_distribucion.index, supervivencia_distribucion.values, marker='o', linestyle='-', color='salmon', markersize=8)

# Títulos y etiquetas
plt.title('Distribución de Meses de Supervivencia', fontsize=16)
plt.xlabel('Meses de Supervivencia', fontsize=14)
plt.ylabel('Número de Pacientes', fontsize=14)
plt.grid(True)  # Agregar cuadrícula

# Mostrar la visualización
plt.show()

"""**Promedio de Meses de Supervivencia por Diferenciación y Grado del Tumor**

* Descripción: Gráfico de barras que muestra el promedio de meses de supervivencia para diferentes combinaciones de diferenciación celular y grado del tumor.

**Interpretación:**

1. Eje X (Diferenciación y Grado del Tumor): Cada barra representa una combinación específica de características del tumor.

2. Eje Y (Promedio de Meses de Supervivencia): Indica el valor promedio de meses de supervivencia para cada combinación.

3. Utilidad: Permite comparar cómo influyen la diferenciación celular y el grado del tumor en la supervivencia promedio de los pacientes. Las barras más altas indican combinaciones que podrían estar asociadas con una mejor supervivencia.
"""

# Calcular el promedio de meses de supervivencia por diferenciación y grado del tumor
promedio_supervivencia_por_diferenciacion_grado = df.groupby(['differentiate', 'Grade'])['Survival Months'].mean()

# Mostrar el resultado
print(promedio_supervivencia_por_diferenciacion_grado)

# Configuración de la figura
plt.figure(figsize=(12, 8))

# Gráfico de barras para mostrar el promedio
grafico = promedio_supervivencia_por_diferenciacion_grado.plot(kind='bar', color='salmon', edgecolor='black')

# Títulos y etiquetas
plt.title('Promedio de Meses de Supervivencia por Diferenciación y Grado del Tumor', fontsize=16)
plt.xlabel('Diferenciación y Grado del Tumor', fontsize=14)
plt.ylabel('Promedio de Meses de Supervivencia', fontsize=14)
plt.xticks(rotation=45, ha='right')  # Rotar etiquetas del eje x para mejor visualización

# Cambiar las etiquetas del eje x a español
etiquetas = [f'{dif}\n{grade}' for dif, grade in promedio_supervivencia_por_diferenciacion_grado.index]
grafico.set_xticklabels(etiquetas, rotation=0)

# Mostrar el valor numérico encima de cada barra
for idx, value in enumerate(promedio_supervivencia_por_diferenciacion_grado):
    grafico.text(idx, value + 1, f'{value:.2f}', ha='center', color='black', fontsize=10)

# Mostrar la visualización
plt.tight_layout()
plt.show()

"""**Relación entre Diferenciación Celular y Supervivencia**

* Descripción: Gráfico de violín que muestra la distribución de los meses de supervivencia según el tipo de diferenciación celular del tumor.

**Interpretación:**

1. Eje X (Diferenciación Celular): Categorías de diferenciación celular del tumor.

2. Eje Y (Meses de Supervivencia): Rango de valores de supervivencia y su densidad de distribución para cada tipo de diferenciación.

3. Utilidad: Permite visualizar si hay diferencias significativas en los períodos de supervivencia entre diferentes tipos de diferenciación celular. Los violines más anchos indican una mayor variabilidad en la supervivencia.
"""

# Tabla de distribución de Diferenciación Celular y Meses de Supervivencia
differentiation_survival_table = df.groupby('differentiate')['Survival Months'].describe().reset_index()
print(differentiation_survival_table)

# Colores
colores_cancer_mama = ['#FFB6C1', '#FF69B4', '#FF1493', '#C71585', '#DB7093']

# Diferenciación Celular y Supervivencia
plt.figure(figsize=(12, 8))
sns.violinplot(x='differentiate', y='Survival Months', data=df, palette=colores_cancer_mama)
plt.title('Relación entre Diferenciación Celular y Supervivencia')
plt.xlabel('Diferenciación Celular')
plt.ylabel('Meses de Supervivencia')
plt.show()

"""**Distribución de Etapas del Tumor**

* Descripción: Gráfico circular que muestra la proporción de pacientes en cada etapa del tumor.

**Interpretación:**

1. Segmentos del Círculo: Cada segmento representa una categoría de etapa del tumor.

2. Proporción: El tamaño relativo de cada segmento indica la proporción de pacientes en esa etapa del tumor con respecto al total.

3. Utilidad: Proporciona una visión rápida de cómo se distribuyen las etapas del tumor en el conjunto de datos, destacando las proporciones relativas de cada etapa.
"""

# Tabla de distribución de Etapas del Tumor
tumor_stage_distribution = df['6th Stage'].value_counts().reset_index()
tumor_stage_distribution.columns = ['Etapa del Tumor', 'Frecuencia']
print(tumor_stage_distribution)

# Colores
colores_cancer_mama = ['#FFB6C1', '#FF69B4', '#FF1493', '#C71585', '#DB7093']

# Distribución de etapas del tumor en forma de gráfico circular (pie chart)
plt.figure(figsize=(10, 10))
df['6th Stage'].value_counts().plot.pie(autopct='%1.1f%%', colors=colores_cancer_mama)
plt.title('Distribución de Etapas del Tumor')
plt.ylabel('')  # Eliminar etiqueta del eje y
plt.show()

"""**Relación entre Edad y Tamaño del Tumor con respecto a Supervivencia**

* Descripción: Gráfico de dispersión con burbujas que muestra la relación entre la edad de los pacientes, el tamaño del tumor y los meses de supervivencia.

**Interpretación:**

1. Eje X (Edad): Edad de los pacientes.

2. Eje Y (Tamaño del Tumor): Tamaño del tumor, representado por el tamaño de las burbujas.

3. Color y Tamaño de las Burbujas: Indican los meses de supervivencia, donde colores más cálidos y burbujas más grandes representan períodos más largos de supervivencia.

4. Utilidad: Permite explorar cómo la edad y el tamaño del tumor se relacionan con la supervivencia de los pacientes, identificando patrones visuales y posibles correlaciones.
"""

# Tabla de relación entre Edad y Tamaño del Tumor
age_tumor_size_relation = df[['Age', 'Tumor Size']].groupby('Age').mean().reset_index()
print(age_tumor_size_relation)

# Relación entre Edad y Tamaño del Tumor
plt.figure(figsize=(14, 10))
scatter = sns.scatterplot(x='Age', y='Tumor Size', hue='Survival Months', size='Survival Months', sizes=(30, 200),
                          data=df, palette='coolwarm', alpha=0.8)
scatter.legend(title='Meses de Supervivencia', title_fontsize='12', loc='upper right', bbox_to_anchor=(1.25, 1))
plt.title('Relación entre Edad y Tamaño del Tumor con respecto a Supervivencia (Gráfico de Burbujas)')
plt.xlabel('Edad')
plt.ylabel('Tamaño del Tumor')
plt.show()

"""### Evaluación del Rendimiento.

### Generar modelos complementarios
### Exploración y preprocesamiento de datos:
Realiza una exploración detallada de los datos para comprender la distribución de las características y la variable objetivo.

Maneja cualquier valor atípico o dato faltante de manera apropiada.

Convierte las variables categóricas en variables dummy si es necesario.

### División de datos:
Divide el conjunto de datos en conjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo.

### Selección de modelos:
Considera modelos adecuados para la clasificación, como árboles de decisión, Random Forest, Support Vector Machines (SVM), y modelos de regresión logística.

Puedes experimentar con varios modelos para evaluar su rendimiento.

### Entrenamiento y ajuste de hiperparámetros:
Entrena los modelos seleccionados en el conjunto de entrenamiento y ajusta sus hiperparámetros utilizando técnicas como la validación cruzada.

Utiliza métricas de evaluación, como precisión, recall, F1-score y área bajo la curva ROC (AUC-ROC), para comparar el rendimiento de los modelos.

### Evaluación del rendimiento:
Evalúa el rendimiento de los modelos en el conjunto de prueba utilizando las métricas mencionadas anteriormente.

Observa si hay un desequilibrio en la clase objetivo y tenlo en cuenta al interpretar las métricas.

## Identificación de overfitting o underfitting:
Utiliza gráficos de curvas de aprendizaje para observar si hay signos de overfitting o underfitting. Si las curvas de entrenamiento y prueba divergen, podría ser un indicador de overfitting.

Examina las métricas de rendimiento en el conjunto de entrenamiento y prueba. Si la precisión es alta en el conjunto de entrenamiento pero baja en el conjunto de prueba, podría haber overfitting.

### Mejoras potenciales:
Si hay signos de overfitting, considera técnicas como la regularización, la reducción de la complejidad del modelo o la recolección de más datos.

Si hay signos de underfitting, puedes probar con modelos más complejos o ajustar mejor los hiperparámetros.

### Validación cruzada:
Utiliza la validación cruzada para obtener estimaciones más robustas del rendimiento del modelo.

#Identificar por medio de métricas.
### Overfitting:

Señales: El modelo tiene un rendimiento excelente en el conjunto de entrenamiento, pero un rendimiento inferior en el conjunto de prueba.
Métricas afectadas: Precisión, recall, F1-score en el conjunto de prueba.

Posibles causas:
El modelo es demasiado complejo y se ha ajustado demasiado a los datos de entrenamiento.
Pocas muestras de datos o características, lo que permite al modelo memorizar en lugar de generalizar.

Formas de mejora:
Reducir la complejidad del modelo, por ejemplo, ajustando los hiperparámetros o utilizando técnicas de regularización.
Aumentar la cantidad de datos de entrenamiento para proporcionar una visión más completa del espacio de características.

## Underfitting:

Señales: El modelo tiene un rendimiento deficiente tanto en el conjunto de entrenamiento como en el conjunto de prueba.
Métricas afectadas: Precisión, recall, F1-score en ambos conjuntos.

Posibles causas:
El modelo es demasiado simple para capturar la complejidad de los datos.
Pocas iteraciones durante el entrenamiento o falta de ajuste de hiperparámetros.

Formas de mejora:
Aumentar la complejidad del modelo si es necesario, por ejemplo, agregar capas a una red neuronal o aumentar la profundidad de un árbol de decisión.
Ajustar hiperparámetros para encontrar la configuración óptima del modelo.

## Optimización de hiperparámetros:

Señales: Los hiperparámetros no están optimizados, lo que afecta al rendimiento del modelo.
Métricas afectadas: Diversas métricas dependiendo de la configuración de los hiperparámetros.

Posibles causas:
No se han ajustado adecuadamente los hiperparámetros durante el entrenamiento.

Formas de mejora:
Utilizar técnicas de búsqueda de hiperparámetros, como Grid Search o Random Search, para encontrar la combinación óptima.
Realizar validación cruzada para evaluar el rendimiento del modelo en diferentes divisiones de los datos.

**Explicación del Proyecto de Análisis y Modelado Predictivo de Datos de Cáncer de Mama**

Este proyecto utiliza técnicas de aprendizaje automático para analizar datos de pacientes con cáncer de mama y predecir su supervivencia. A continuación, se detalla el flujo de trabajo:

1. **Preprocesamiento de Datos:**

  * Codificación de Variables Categóricas: Las variables categóricas como raza, estado marital y estado de los receptores hormonales se codifican numéricamente para su procesamiento por modelos de aprendizaje automático.

  * Eliminación de Columnas No Numéricas y Escalado de Características: Se eliminan las columnas 'Survival Months' (meses de supervivencia, la variable objetivo) y 'Status' (estado del paciente) del conjunto de datos. Las características restantes se escalan para modelos que requieren datos estandarizados.

2. **Selección y Entrenamiento de Modelos:**

  * Se seleccionan tres modelos de clasificación: Random Forest, SVM y Regresión Logística.

  * Cada modelo se entrena utilizando los datos de entrenamiento preparados previamente.

3. **Evaluación del Rendimiento:**

  * Se evalúan los modelos utilizando métricas estándar como exactitud, precisión, recall, puntuación F1 y AUC-ROC (área bajo la curva ROC).

  * Se genera una matriz de confusión para cada modelo, mostrando cómo clasifica correctamente e incorrectamente las etiquetas de supervivencia ('Alive' o 'Dead').

  * Se utilizan gráficos de curvas de aprendizaje para visualizar cómo varía el rendimiento del modelo con respecto al tamaño del conjunto de entrenamiento.

4. **Validación Cruzada:**

  * Se realiza validación cruzada para estimar la precisión media del modelo en diferentes divisiones de los datos de entrenamiento.
  
Este enfoque sistemático permite comparar y seleccionar el modelo más adecuado para predecir la supervivencia de pacientes con cáncer de mama, proporcionando información valiosa para decisiones clínicas y estrategias de tratamiento personalizadas.
"""

# Cargar los datos
df = pd.read_csv ("/content/drive/MyDrive/Colab Notebooks/1. Breast_Cancer/Breast_Cancer.csv")

# Manejo de valores atípicos y datos faltantes
df = df.dropna()  # Eliminar filas con datos faltantes
df = shuffle(df, random_state=42)  # Mezclar los datos

# Codificar variables categóricas con LabelEncoder
label_encoder = LabelEncoder()

# Añade todas las columnas categóricas que necesitas codificar
categorical_columns = ['Race', 'Marital Status', '6th Stage', 'differentiate', 'Estrogen Status', 'Progesterone Status', 'T Stage ', 'N Stage']

# Iterar sobre todas las columnas del DataFrame
for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = label_encoder.fit_transform(df[col])

# Verifica si las columnas objetivo aún existen
if 'Status' not in df.columns:
    raise ValueError("La columna 'Status' no se encontró en el DataFrame después de la limpieza.")

# División de datos en entrenamiento y prueba si hay suficientes datos
if df.shape[0] > 0:
    X = df.drop(['Survival Months', 'Status'], axis=1)
    y = df['Status']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Escalar características para modelos sensibles a la escala
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Selección de modelos
models = {
    'Bosque aleatorio': RandomForestClassifier(random_state=42),
    'SVM': SVC(random_state=42),
    'Regresión logística': LogisticRegression(random_state=42)
}

# Entrenamiento y ajuste de hiperparámetros
for model_name, model in models.items():
    model.fit(X_train_scaled, y_train)

# Evaluación del rendimiento
for model_name, model in models.items():
    y_pred = model.predict(X_test_scaled)
    print(f"\n{model_name} Metricas:")
    print(f"Exactitud: {accuracy_score(y_test, y_pred)}")
    print(f"Precisión: {precision_score(y_test, y_pred)}")
    print(f"Recordar: {recall_score(y_test, y_pred)}")
    print(f"Puntuación F1: {f1_score(y_test, y_pred)}")
    print(f"AUC-ROC: {roc_auc_score(y_test, y_pred)}")
    print(f"Matriz de confusión:\n{confusion_matrix(y_test, y_pred)}")

# Identificación de overfitting o underfitting
# Gráficos de curvas de aprendizaje
def plot_learning_curve(model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 5)):
    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=cv, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)

    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_scores_mean, label='Puntuación de entrenamiento', color='skyblue')
    plt.plot(train_sizes, test_scores_mean, label='Puntuación de validación cruzada', color='salmon')
    plt.title(f'Curva de aprendizaje - {model.__class__.__name__}')
    plt.xlabel('Ejemplos de entrenamiento')
    plt.ylabel('Puntaje')
    plt.legend(loc='best')
    plt.show()

# Ejemplo de uso
plot_learning_curve(models['Regresión logística'], X_train_scaled, y_train)

# Validación cruzada
cv_scores = cross_val_score(models['Regresión logística'], X_train_scaled, y_train, cv=5, scoring='accuracy')
print(f"Precisión de validación cruzada: {np.mean(cv_scores)}")

# Experimenta y ajusta los modelos y sus parámetros según sea necesario
# Realiza mejoras potenciales y ajusta el código según tus necesidades específicas.

"""### Estructurando un Proyecto de DS PARTE 3

1. **Selección de Método de Feature Selection**

El método de selección de características es crucial para reducir la dimensionalidad y mejorar la eficiencia del modelo. Aquí algunos métodos comunes que podrías considerar:

* Selección basada en modelos: Utiliza modelos de aprendizaje automático para determinar la importancia de cada característica.

  * Ejemplo: Utilizar Random Forest para calcular la importancia de las características.

* Selección univariada: Evalúa cada característica de forma independiente utilizando pruebas estadísticas.

  * Ejemplo: Prueba chi-cuadrado para características categóricas o correlación de Pearson para características numéricas.

* Eliminación recursiva de características: Elimina iterativamente las características menos importantes.

  * Ejemplo: Recursive Feature Elimination (RFE) con validación cruzada.
Elige el método que mejor se adapte a tus datos y objetivos específicos.

2. Elección de Algoritmo de Regresión o Clasificación
Dependiendo de la naturaleza de tu problema (regresión o clasificación) y de los datos seleccionados después de aplicar el método de selección de características, puedes elegir diferentes algoritmos de aprendizaje automático:

* Regresión:
  * Regresión lineal
  * Regresión logística (para problemas de clasificación binaria)
  * Árboles de decisión para regresión
  * Clasificación:
  * Árboles de decisión
  * Bosques aleatorios
  * Máquinas de vectores de soporte (SVM)
  * Redes neuronales
  * Selecciona al menos uno de estos algoritmos basándote en la naturaleza de tu problema y los requisitos de precisión y velocidad.

3. Cálculo de Métricas para Validar el Modelo
Una vez entrenado el modelo, es fundamental evaluar su rendimiento utilizando métricas adecuadas:

* Regresión:
  * Error cuadrático medio (MSE)
  * Coeficiente de determinación (R^2)
  * Clasificación:
  * Exactitud (accuracy)
  * Precisión, recall y F1-score (especialmente importante si hay desequilibrio de clases)
  * Área bajo la curva ROC (AUC-ROC) para problemas binarios.
  * Utiliza estas métricas para comparar diferentes modelos y seleccionar el más adecuado.

4. Generación de Conclusiones
Finalmente, basándote en los resultados obtenidos de la evaluación del modelo, genera conclusiones que ayuden a responder las preguntas de investigación o los objetivos del proyecto.

Algunos puntos clave para considerar:

¿Qué características fueron más importantes para el modelo?
¿Qué algoritmo proporcionó el mejor rendimiento según las métricas elegidas?
¿Hay problemas de overfitting o underfitting que deban abordarse?
¿Cómo se pueden aplicar estos resultados en un contexto práctico?
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectKBest, chi2, RFE
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder, MinMaxScaler

# Cargar los datos
df = pd.read_csv ("/content/drive/MyDrive/Colab Notebooks/1. Breast_Cancer/Breast_Cancer.csv")

# Ajuste según la columna correcta para el diagnóstico
target_column = 'Status'  # Ajusta este valor si el nombre de la columna es diferente

# Verificar si la columna de diagnóstico existe
if target_column not in df.columns:
    raise KeyError(f"'{target_column}' not found in DataFrame columns")

# Preparar los datos
X = df.drop(target_column, axis=1)
y = df[target_column]

# Convertir etiquetas de texto a números
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Identificar columnas categóricas y aplicar one-hot encoding
categorical_columns = X.select_dtypes(include=['object']).columns
X_encoded = pd.get_dummies(X, columns=categorical_columns)

# Escalar las características numéricas usando MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X_encoded)

# Selección basada en modelos con Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_scaled, y_encoded)
importances = rf.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': X_encoded.columns, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

print("Importancia de las características según Random Forest:")
print(feature_importance_df)

# Selección univariada con prueba chi-cuadrado
chi2_selector = SelectKBest(chi2, k=10)
X_kbest = chi2_selector.fit_transform(X_scaled, y_encoded)
selected_features = X_encoded.columns[chi2_selector.get_support()]

print("Características seleccionadas según prueba chi-cuadrado:")
print(selected_features)

# Eliminación recursiva de características (RFE) con regresión logística
model = LogisticRegression(max_iter=10000)
rfe = RFE(model, n_features_to_select=10)
fit = rfe.fit(X_scaled, y_encoded)
selected_features_rfe = X_encoded.columns[fit.support_]

print("Características seleccionadas según RFE:")
print(selected_features_rfe)

"""**Regresión logística**"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve

# Dividir los datos en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)

# Entrenar el modelo
logreg = LogisticRegression(max_iter=10000)
logreg.fit(X_train, y_train)

# Predecir y evaluar
y_pred = logreg.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# ROC-AUC
y_prob = logreg.predict_proba(X_test)[:, 1]
auc_score = roc_auc_score(y_test, y_prob)
print("AUC-ROC:", auc_score)
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

"""**Random Forest**"""

from sklearn.ensemble import RandomForestClassifier

# Entrenar el modelo
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predecir y evaluar
y_pred_rf = rf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

# ROC-AUC
y_prob_rf = rf.predict_proba(X_test)[:, 1]
auc_score_rf = roc_auc_score(y_test, y_prob_rf)
print("AUC-ROC:", auc_score_rf)
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_prob_rf)
plt.plot(fpr_rf, tpr_rf, label=f'AUC = {auc_score_rf:.2f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

"""**Conclusiones**

**Importancia de las características**

La selección de características utilizando Random Forest reveló que las características más importantes son:

1. **Survival Months**: 0.355
2. **Age**: 0.113
3. **Regional Node Examined**: 0.098
4. **Tumor Size**: 0.098
5. **Reginol Node Positive**: 0.068

Estas características demostraron tener una alta importancia en la predicción del estado del paciente.

**Algoritmos de clasificación**

Probamos dos algoritmos de clasificación: Regresión Logística y Random Forest. Ambos algoritmos fueron evaluados utilizando un conjunto de datos de prueba, y las métricas clave fueron las siguientes:

**Regresión Logística**

- **Exactitud (Accuracy):** 0.8333
- **Reporte de clasificación:**
          precision    recall  f1-score   support

       0       0.85      0.91      0.88       191
       1       0.83      0.74      0.78       109

accuracy                           0.85       300


macro avg 0.82 0.82 0.82 300

weighted avg 0.83 0.83 0.83 300

- **AUC-ROC:** 0.89


**Random Forest**

- **Exactitud (Accuracy):** 0.8467
- **Reporte de clasificación:**
          precision    recall  f1-score   support

       0       0.85      0.91      0.88       191
       1       0.83      0.74      0.78       109

accuracy                           0.85       300

macro avg 0.84 0.83 0.83 300

weighted avg 0.85 0.85 0.84 300

- **AUC-ROC:** 0.92

---

**Comparación de algoritmos**

Al comparar los resultados de ambos algoritmos, observamos que:

- **Random Forest** generalmente obtuvo un mejor rendimiento en términos de AUC-ROC, lo que indica que es más efectivo para distinguir entre las clases.
- **Regresión Logística** también tuvo un buen rendimiento, pero en algunos casos fue superada por Random Forest.

**Problemas de overfitting/underfitting**

No se detectaron problemas significativos de overfitting o underfitting en los modelos entrenados, ya que ambos mostraron un buen equilibrio entre el conjunto de entrenamiento y el conjunto de prueba.

**Aplicabilidad práctica**

Los resultados de este análisis pueden ser utilizados en un contexto clínico para predecir el estado del paciente basado en las características más importantes identificadas. Específicamente:

- **Survival Months** y **Age** son factores cruciales que deben ser considerados en el seguimiento y tratamiento de los pacientes.
- La **cantidad de nodos examinados y positivos** y el **tamaño del tumor** son también indicadores importantes de la progresión del cáncer y pueden ayudar en la toma de decisiones clínicas.

---

**Recomendaciones**

1. **Implementación en práctica clínica:** Los modelos desarrollados pueden ser implementados en sistemas de soporte de decisiones clínicas para ayudar a los médicos a evaluar el estado de los pacientes y planificar el tratamiento adecuado.
  
2. **Mejorar la recolección de datos:** Es importante continuar recolectando datos de alta calidad y actualizados para mejorar la precisión de los modelos en el futuro.

3. **Monitoreo continuo:** Los modelos deben ser monitoreados y actualizados regularmente para asegurarse de que continúan proporcionando predicciones precisas y relevantes.

**Próximos pasos**

1. **Validación externa:** Probar los modelos en un conjunto de datos externo para verificar su generalización y robustez.
2. **Optimización de hiperparámetros:** Realizar una búsqueda más exhaustiva de hiperparámetros para optimizar aún más el rendimiento de los modelos.
3. **Incorporación de nuevas características:** Explorar la inclusión de nuevas características que puedan mejorar la capacidad predictiva de los modelos.

### Modelo de Jupyter Notebook

Jupyter Notebook - Análisis y Modelado de Datos de Cáncer de Mama

1. Abstracto con motivación y audiencia:
Motivación:
Este análisis tiene como objetivo extraer conocimientos valiosos de un conjunto de datos tabulares para informar decisiones prácticas. La motivación radica en aplicar un enfoque alternativo, proporcionando recomendaciones accionables y orientadas a resultados.

Audiencia:
Profesionales de la industria y tomadores de decisiones que buscan insights específicos y aplicables a su contexto. El análisis se centra en ofrecer información práctica derivada de los datos tabulares.

2. Preguntas/Hipótesis:
Eficiencia del Tratamiento:

¿Existen patrones en la eficiencia del tratamiento relacionados con variables específicas?
Segmentación de Pacientes:

¿Es posible identificar grupos específicos de pacientes con características similares que responden de manera similar al tratamiento?
Tendencias Temporales:

¿Se observan tendencias temporales en la eficacia del tratamiento a lo largo del tiempo?

3. Estructura:

Introducción y Motivación:
Descripción del conjunto de datos y cambio en el enfoque.

Objetivos e Hipótesis:
Presentación de las nuevas preguntas e hipótesis.

Exploración de Datos (EDA) - Enfoque Alternativo:
Visualización de nuevas características y relaciones.

Análisis de Segmentación de Pacientes:
Identificación de grupos y evaluación de la respuesta al tratamiento.

Tendencias Temporales en la Eficacia del Tratamiento:
Visualización y análisis de variaciones temporales.

Conclusiones y Recomendaciones Prácticas:
Resumen de hallazgos clave y recomendaciones basadas en nuevas preguntas.

4. Análisis Exploratorio de Datos (EDA):

Exploración de Nuevas Variables:
Identificación de características adicionales relevantes.

Análisis de Correlación y Causalidad:
Investigación de correlaciones y posibles relaciones causales.

Enfoque en Resultados Clínicos:
Visualización de resultados clínicos y su relación con variables seleccionadas.
Este enfoque se centra en brindar una visión general y estructurada, manteniendo la simplicidad y enfocándose en los nuevos aspectos del análisis.

Muestra la distribución del tamaño del tumor para pacientes en diferentes estados (vivo o fallecido).

Mustra la distribución de los datos y la probabilidad de cada valor.

Las partes más anchas del violín indican mayor densidad de datos.

Permite observar si hay diferencias significativas en el tamaño del tumor entre pacientes vivos y fallecidos.

* Eje X: Estado del Tumor (Status), donde "0" representa que el paciente está vivo y "1" representa que el paciente ha fallecido.
* Eje Y: Tamaño del Tumor (Tumor Size).
"""

#Relación entre el Tamaño del Tumor y el Estado del Tumor.
#Visualiza la distribución del tamaño del tumor según el estado del tumor.

plt.figure(figsize=(12, 8))
sns.violinplot(x='Status', y='Tumor Size', data=df, palette='coolwarm')
plt.title('Relación entre el Tamaño del Tumor y el Estado del Tumor')
plt.xlabel('Estado del Tumor')
plt.ylabel('Tamaño del Tumor')
plt.show()

"""Muestra la cantidad de pacientes en diferentes estados del tumor y cómo varía su supervivencia en meses. Cada barra representa el número total de pacientes en un estado específico (vivo o fallecido), y los colores dentro de las barras indican los diferentes rangos de supervivencia en meses.

Este gráfico permite identificar visualmente si la supervivencia está asociada con el estado del tumor.

* Eje X: Estado del Tumor (Status), donde "0" representa que el paciente está vivo y "1" representa que el paciente ha fallecido.
* Eje Y: Número de Pacientes.
* Hue: Survival Months, los meses de supervivencia, para diferenciar la cantidad de meses de supervivencia dentro de cada estado del tumor.
"""

#Comparación de la Supervivencia según el Estado del Tumor.
#Analiza cómo la supervivencia varía entre diferentes estados del tumor.

plt.figure(figsize=(12, 8))
sns.countplot(x='Status', hue='Survival Months', data=df, palette='coolwarm')
plt.title('Supervivencia según el Estado del Tumor')
plt.xlabel('Estado del Tumor, Alive "0", Dead "1"')
plt.ylabel('Número de Pacientes')
plt.show()

"""Muestra la distribución de las edades de los pacientes según su estado del tumor (vivo o fallecido). Similar al primer gráfico, proporciona información sobre la densidad y distribución de las edades.

Las áreas más anchas indican una mayor concentración de datos.

Puede revelar si hay diferencias significativas en las edades de los pacientes vivos y fallecidos, lo que podría sugerir una relación entre la edad y la supervivencia en pacientes con cáncer de mama.

* Eje X: Estado del Tumor (Status), donde "0" representa que el paciente está vivo y "1" representa que el paciente ha fallecido.
* Eje Y: Edad (Age).
"""

#Distribución de Edades en Diferentes Estados del Tumor.
#Examina cómo se distribuyen las edades en diferentes estados del tumor.

plt.figure(figsize=(12, 8))
sns.violinplot(x='Status', y='Age', data=df, palette='coolwarm')
plt.title('Distribución de Edades según el Estado del Tumor')
plt.xlabel('Estado del Tumor')
plt.ylabel('Edad')
plt.show()

"""# Proyecto "Cáncer de mama Wisconsin (Diagnóstico).

### **Presentación.**

A continuación, se presentará el conjunto de datos del Cáncer de Mama Wisconsin (Diagnóstico), el cual complementa el conjunto de datos del Cáncer de Mama de SEER al proporcionar información detallada y específica sobre las características de las masas mamarias.

Este conjunto de datos es fundamental para el análisis y la predicción del diagnóstico de cáncer de mama, ayudando a distinguir entre casos benignos y malignos con mayor precisión.

### **Descripción.**

El conjunto de datos del Cáncer de Mama Wisconsin (Diagnóstico) contiene características detalladas de las masas mamarias obtenidas a partir de imágenes digitalizadas de aspiraciones con aguja fina (PAAF).

Estas características describen los núcleos celulares presentes en la imagen y se utilizan para predecir si el cáncer es benigno o maligno.

**Importancia del Conjunto de Datos**

Este conjunto de datos es crucial para el desarrollo de modelos de aprendizaje automático que pueden ayudar a los médicos a realizar diagnósticos más precisos y rápidos.

Al complementar el conjunto de datos del Cáncer de Mama SEER, se proporciona una imagen más completa y detallada del comportamiento de las masas mamarias, facilitando así la identificación de patrones y características críticas que pueden diferenciar entre masas benignas y malignas.

A continuación, se describen los detalles específicos del conjunto de datos:

### **Variables.**

A continuación se muestra una descripción general de los **Atributos Utilizados**:

* ID Número
* Diagnóstico (M = maligno, B = benigno)
* Se calculan diez características de valor real para cada núcleo celular:
  1. `Radio`: (Media de las distancias desde el centro a los puntos del perímetro).
  2. `Textura`: (Desviación estándar de los valores de escala de grises).
  3. `Perímetro`.
  4. `Área`.
  5. `Suavidad`: (Variación local en longitudes de radio).
  6. `Compacidad`: (Perímetro^2 / área - 1,0).
  7. `Concavidad`: (Severidad de las porciones cóncavas del contorno).
  8. `Puntos Cóncavos`: (Número de porciones cóncavas del contorno).
  9. `Simetría`.
  10. `Dimensión Fractal`: ("Aproximación de la línea costera" - 1).

> Cada una de estas características se calcula de tres maneras diferentes: media, desviación estándar y el peor (o el mayor valor) para cada imagen, resultando en un total de 30 características.

**Conclusión**

El análisis y la utilización del conjunto de datos del Cáncer de Mama Wisconsin (Diagnóstico) permite un enfoque más detallado y preciso en la predicción del diagnóstico del cáncer de mama.

La integración de este conjunto de datos con otros, como el SEER, proporciona una herramienta poderosa para mejorar la precisión diagnóstica y potencialmente salvar vidas mediante detecciones tempranas y tratamientos adecuados.

### **Librerias.**
"""

# Commented out IPython magic to ensure Python compatibility.
# Importación de librerías necesarias

# Tratamiento de datos
# ==============================================================================
import numpy as np                    # Importar Numpy
import pandas as pd                   # Importar Pandas
import scipy as sp
from prettytable import PrettyTable

# Gráficos
# ==============================================================================
import matplotlib.pyplot as plt       # El modulo Pyplot de Matplotlib
import seaborn as sns                 # Importar Seaborn
import matplotlib as mpl              # Importar MatPlotLib
import plotly.express as px

mpl.style.use('bmh')    # Establecemos un nuevo estilo

# Preprocesado y modelado
# ==============================================================================
from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.utils import resample
from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
import xgboost as xgb

# Métricas
# ==============================================================================
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import roc_curve, roc_auc_score, mean_squared_error

# Configuración de advertencias
# ==============================================================================
import warnings
warnings.filterwarnings('ignore')

# Otros
# ==============================================================================
# %config IPCompleter.greedy=True
import xlrd
from matplotlib.ticker import PercentFormatter
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.svm import SVC
from sklearn.utils import shuffle
from sklearn.impute import SimpleImputer

"""#### **Conectar a una API.**

* Instalar la biblioteca: La mayoría de las veces, requests ya está instalada en Colab, pero puedes asegurarte instalándola nuevamente.

!pip install requests

* Importar la biblioteca: Importar requests.

import requests

* Realizar una solicitud a la API: Dependiendo del tipo de solicitud (GET, POST, etc.), utilizarás diferentes métodos de requests.

* Procesar la respuesta: Recibirás la respuesta en formato JSON, que puedes convertir en un diccionario de Python para su manipulación.
"""

from google.colab import files

from google.colab import drive
drive.mount('/content/gdrive')

df = pd.read_csv ("/content/gdrive/MyDrive/Colab Notebooks/1. Breast_Cancer/Data_Complementario.csv")
df.shape

"""## **DataSet Complementario**
### **Descripción General de los Datos**

* Total de muestras: 569
* Diagnósticos: 357 benignos, 212 malignos
* Atributos sin valores faltantes
* Valores recodificados con cuatro dígitos significativos

**Exploración de Datos**
* Media de Radio vs. Textura: Se puede usar un gráfico de dispersión para visualizar la distribución de los diagnósticos.
* Diagramas de dispersión para cada par de características en el conjunto de datos, donde cada punto en el diagrama de dispersión representa una instancia de datos

**Análisis de Datos**
* Las características de concavidad y puntos cóncavos muestran una relación significativa con la malignidad de las masas mamarias.
* Se utilizan visualizaciones impactantes como gráficos de dispersión y mapas de calor para presentar hallazgos.

**Conclusiones**
* Los análisis indican que ciertos atributos, como la concavidad y los puntos cóncavos, son críticos para predecir la malignidad.
* Estos hallazgos pueden mejorar la precisión y la rapidez del diagnóstico del cáncer de mama.

**Previsualización de los Datos**

A continuación, se mostrarán datos del conjunto de datos sobre cáncer de mama para llevar a cabo una previsualización inicial. Esta visualización nos permitirá tener una primera impresión sobre la distribución de las variables y la integridad de los datos:
"""

df.head (10)

df.info()

df.describe()

"""### **Data Storytelling: Explorando el Diagnóstico del Cáncer de Mama con Datos.**

**Inicio:**
En el ámbito de la medicina, las decisiones críticas para la salud de las personas pueden revolucionarse con la ayuda de datos precisos y análisis avanzados.

Este conjunto de datos nos proporciona la oportunidad de mejorar el diagnóstico del cáncer de mama.

**Nudo:**
Con una variedad de características que describen núcleos celulares en imágenes de aspiraciones, cada atributo podría ser clave para predecir si una masa es benigna o maligna.

¿Cómo podemos utilizar esta información de manera efectiva?

**Desarrollo:**
Explorando características relevantes, identificamos relaciones significativas entre atributos como la textura y la concavidad con la malignidad.

Utilizando visualizaciones, mostramos cómo estas características pueden ayudar en la clasificación.

**Desenlace:**
Imaginemos un futuro donde, gracias a estos datos, los diagnósticos sean más precisos y tempranos, salvando vidas y ofreciendo mayor tranquilidad a los pacientes.

Estos datos no son solo números, sino una herramienta poderosa en la lucha contra el cáncer.

**Elevator Pitch:**
¿Qué pasaría si pudiéramos predecir el cáncer de mama con mayor precisión? Con este conjunto de datos, estamos un paso más cerca de ese objetivo.

Exploramos características celulares para desvelar secretos que podrían salvar vidas.

### **Preguntas de Interés:**

* ¿Existe una relación entre el tamaño medio de la masa mamaria y su diagnóstico de benigno o maligno?

* ¿Las características relacionadas con la textura de la masa mamaria pueden predecir su malignidad?

* ¿Hay alguna correlación entre la suavidad de la masa mamaria y su diagnóstico de cáncer?

* ¿Las masas mamarias con mayor compacidad tienden a ser más malignas?

* ¿La concavidad de la masa mamaria está relacionada con la severidad de su diagnóstico?

* ¿Existen diferencias significativas en la distribución de diagnósticos según las diferentes características?

Muestra que las masas malignas tienden a tener un radio medio mayor que las benignas. Esto indica que el tamaño medio de las masas puede ser un factor importante en el diagnóstico de malignidad.

Las estadísticas descriptivas proporcionan información adicional sobre la media, mediana, y el rango intercuartil (IQR) del radio medio para los diagnósticos benignos y malignos. Se observa que las masas malignas tienen una media y mediana del radio medio más altas en comparación con las benignas.
"""

# Pregunta de Hipótesis 1: Relación entre el Tamaño Medio de la Masa Mamaria y su Diagnóstico
# Comparación del radio medio entre diagnósticos
sns.boxplot(data=df, x='diagnosis', y='radius_mean', palette={'B': 'skyblue', 'M': 'salmon'})
plt.title('Comparación del Radio Medio entre Diagnósticos')
plt.xlabel('Diagnóstico')
plt.ylabel('Radio Medio')
plt.show()
# Estadística descriptiva
print(df.groupby('diagnosis')['radius_mean'].describe())

"""Indica que las masas malignas tienden a tener una textura media mayor en comparación con las benignas. Esto sugiere que la textura de las masas puede estar asociada con la malignidad.

Las estadísticas descriptivas muestran que la textura media es generalmente más alta en masas malignas, lo que refuerza la observación de la visualización.
"""

# Pregunta de Hipótesis 2: Textura y Malignidad
# Comparación de la textura media entre diagnósticos
sns.boxplot(data=df, x='diagnosis', y='texture_mean', palette={'B': 'skyblue', 'M': 'salmon'})
plt.title('Comparación de la Textura Media entre Diagnósticos')
plt.xlabel('Diagnóstico')
plt.ylabel('Textura Media')
plt.show()
# Estadística descriptiva
print(df.groupby('diagnosis')['texture_mean'].describe())

"""La suavidad media muestra que hay una diferencia notable en la suavidad media entre las masas benignas y malignas, con las masas malignas tendiendo a tener una suavidad media ligeramente menor.

Las estadísticas descriptivas confirman que la suavidad media es un poco menor en masas malignas, aunque la diferencia puede no ser tan pronunciada como en otras características.
"""

# Pregunta de Hipótesis 3: Suavidad y Diagnóstico
# Comparación de la suavidad media entre diagnósticos
sns.boxplot(data=df, x='diagnosis', y='smoothness_mean', palette={'B': 'skyblue', 'M': 'salmon'})
plt.title('Comparación de la Suavidad Media entre Diagnósticos')
plt.xlabel('Diagnóstico')
plt.ylabel('Suavidad Media')
plt.show()
# Estadística descriptiva
print(df.groupby('diagnosis')['smoothness_mean'].describe())

"""La compacidad media muestra que las masas malignas tienden a tener una compacidad media mayor en comparación con las benignas. Esto indica que la compacidad puede ser un factor significativo en la determinación de la malignidad.

Las estadísticas descriptivas revelan que la compacidad media es notablemente más alta en masas malignas, lo cual está alineado con la observación del boxplot.
"""

# Pregunta de Hipótesis 4: Compacidad y Malignidad
# Comparación de la compacidad media entre diagnósticos
sns.boxplot(data=df, x='diagnosis', y='compactness_mean', palette={'B': 'skyblue', 'M': 'salmon'})
plt.title('Comparación de la Compacidad Media entre Diagnósticos')
plt.xlabel('Diagnóstico')
plt.ylabel('Compacidad Media')
plt.show()
# Estadística descriptiva
print(df.groupby('diagnosis')['compactness_mean'].describe())

"""La concavidad media muestra que las masas malignas tienen una concavidad media significativamente mayor que las benignas. La concavidad es una característica importante en la evaluación de la malignidad de las masas mamarias.

Las estadísticas descriptivas refuerzan que la concavidad media es mucho mayor en masas malignas, lo que respalda la hipótesis de que la concavidad es un indicador crítico de la malignidad.
"""

# Pregunta de Hipótesis 5: Concavidad y Severidad del Diagnóstico
# Comparación de la concavidad media entre diagnósticos
sns.boxplot(data=df, x='diagnosis', y='concavity_mean', palette={'B': 'skyblue', 'M': 'salmon'})
plt.title('Comparación de la Concavidad Media entre Diagnósticos')
plt.xlabel('Diagnóstico')
plt.ylabel('Concavidad Media')
plt.show()
# Estadística descriptiva
print(df.groupby('diagnosis')['concavity_mean'].describe())

"""## **Análisis Univariado**

El análisis univariado se centra en examinar y describir una sola variable a la vez. En el contexto del conjunto de datos del Cáncer de Mama Wisconsin (Diagnóstico), podemos realizar un análisis univariado para cada una de las características que describen los núcleos celulares de las masas mamarias.

Esto nos permitirá comprender mejor la distribución de cada variable y cómo se relaciona con el diagnóstico de cáncer (benigno o maligno).

### **EDA: Análisis exploratorio de datos**

Shape: Muestra la forma del DataFrame (número de filas y columnas).

PrettyTable: Define una tabla con las columnas 'Column', 'Type', 'Non-Null', 'Nulls', 'Unique' y 'Example'.

Bucle for: Recorre cada columna del DataFrame y agrega filas a la tabla:
  * Column: Nombre de la columna.
  * Type: Tipo de datos de la columna.
  * Non-Null: Número de valores no nulos en la columna.
  * Nulls: Número de valores nulos en la columna.
  * Unique: Número de valores únicos en la columna.
  * Example: Ejemplo del primer valor no nulo encontrado en la columna.
"""

from prettytable import PrettyTable

def df_summary(df):
    # Shape of the DataFrame
    print('Shape:', df.shape)

    # Creating a PrettyTable for summary
    t = PrettyTable(['Column', 'Type', 'Non-Null', 'Nulls', 'Unique', 'Example'])

    for c in df.columns:
        t.add_row([
            c,
            df[c].dtype,
            df[c].count(),
            df[c].isnull().sum(),
            df[c].nunique(),
            df[c].dropna().iloc[0] if df[c].nunique() > 0 else ''
        ])

    # Print the table
    print(t)
    print()

# Ejemplo de uso:
df_summary(df)

"""**Estadísticas descriptivas**"""

df.describe().round(2).T

"""**Distribución de los Diagnósticos en el Conjunto de Datos**

Muestra la distribución de los diagnósticos en el conjunto de datos, es decir, cuántas instancias hay de cada tipo de diagnóstico (Benigno o Maligno).
"""

# Distribución de la variable objetivo (Diagnóstico):
# Conteo de diagnósticos
diagnosis_count = df['diagnosis'].value_counts()

# Graficar el conteo con los colores skyblue y salmon
plt.figure(figsize=(6, 4))
sns.countplot(x='diagnosis', data=df, palette={'B': 'skyblue', 'M': 'salmon'})
plt.title('Distribución de Diagnóstico')
plt.xlabel('Diagnóstico - [M]: Maligno [B]: Benigno')
plt.ylabel('Contador')
plt.show()

"""**Explicación:** El gráfico de barras muestra que la mayoría de los diagnósticos en el conjunto de datos son de tipo 'B' (Benigno), con una frecuencia mayor que los diagnósticos de tipo 'M' (Maligno).

Esto indica que el conjunto de datos está desbalanceado, lo cual es importante tener en cuenta al realizar análisis o modelos predictivos, ya que puede afectar la capacidad del modelo para generalizar correctamente.

**Interpretación:** Al observar este gráfico, es evidente que hay una cantidad significativamente mayor de diagnósticos benignos en comparación con los malignos en el conjunto de datos.

Esto puede influir en cómo se interpretan los resultados de análisis posteriores y en cómo se deben manejar los desafíos asociados con conjuntos de datos desbalanceados al construir modelos predictivos.
"""

# Variables numéricas a visualizar
Num_variables = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',
                 'smoothness_mean', 'concavity_mean', 'concave points_mean',
                 'symmetry_mean', 'fractal_dimension_mean']

# Diccionario de traducción
nombre_variable = {
    'radius_mean': 'Radio',
    'texture_mean': 'Textura',
    'perimeter_mean': 'Perímetro',
    'area_mean': 'Área',
    'smoothness_mean': 'Suavidad',
    'concavity_mean': 'Concavidad',
    'concave points_mean': 'Puntos Cóncavos',
    'symmetry_mean': 'Simetría',
    'fractal_dimension_mean': 'Dimensión Fractal'
}

# Filtrar el DataFrame por diagnóstico (suponiendo que tienes una columna 'diagnosis')
benigno = df[df['diagnosis'] == 'B']
maligno = df[df['diagnosis'] == 'M']

# Configuración de subplots
columns = 3
rows = (len(Num_variables) + columns - 1) // columns

# Creación de la figura y subplots
fig, axes = plt.subplots(rows, columns, figsize=(15, 12))

# Iterar sobre las variables numéricas y dibujar los histogramas
for idx, variable in enumerate(Num_variables):
    ax = axes[idx // columns, idx % columns]

    # Dibujar histogramas para benigno y maligno
    sns.histplot(benigno[variable], bins=20, kde=True, color='skyblue', label='Benigno', ax=ax)
    sns.histplot(maligno[variable], bins=20, kde=True, color='salmon', label='Maligno', ax=ax)

    # Obtener el nombre traducido de la variable
    nombre_traducido = nombre_variable.get(variable, variable)

    ax.set_title(f'{nombre_traducido}')
    ax.set_xlabel(nombre_traducido)
    ax.set_ylabel('Contador')
    ax.legend()

plt.tight_layout()
plt.show()

"""**Explicación**

**Radio Medio**
1. Benigno (Azul): La mayoría de los casos benignos tienen un radio medio concentrado en valores menores.
2. Maligno (Rojo): Los casos malignos muestran un rango más amplio de radios medios, con una dispersión mayor hacia valores más altos. Esto indica que las masas malignas tienden a tener un radio medio mayor que las benignas.

El histograma de Radio Medio muestra que la mayoría de las masas mamarias tienen un radio medio que oscila entre aproximadamente 7 y 20 unidades, con una concentración más alta alrededor de los valores 12-15. En los casos benignos, este rango tiende a ser más bajo, mientras que en los malignos se extiende hacia valores más altos, indicando que las masas malignas tienden a ser más grandes en términos de radio medio que las benignas.
Textura Media:

**Textura Medio**
1. Benigno (Azul): La textura media en los casos benignos tiende a estar más concentrada, con una distribución más uniforme y menos variabilidad.
2. Maligno (Rojo): Los casos malignos muestran una textura media más variada y dispersa, con valores que abarcan un rango más amplio. Esto sugiere que las masas malignas pueden presentar texturas más diversas que las benignas.

El histograma de Textura Media indica que la textura media varía significativamente entre las masas mamarias. Hay una concentración notable alrededor de los valores 18-20 en ambos diagnósticos, pero los casos malignos muestran una mayor dispersión y una tendencia hacia texturas más altas en comparación con los benignos. Esto sugiere que las masas malignas pueden presentar una textura media más variada y posiblemente más rugosa en comparación con las masas benignas.

**Perímetro Medio**
1. Benigno (Azul): La distribución del perímetro medio en casos benignos es más compacta y tiende a agruparse en valores menores.
2. Maligno (Rojo): Los casos malignos muestran un rango de perímetros medios más amplio, con una mayor dispersión hacia valores más altos. Esto indica que las masas malignas tienden a tener perímetros mayores en comparación con las benignas.

El histograma de Perímetro Medio muestra que la mayoría de las masas mamarias tienen un perímetro medio que varía entre aproximadamente 50 y 150 unidades, con una concentración mayor en los valores alrededor de 80-120. Los casos malignos tienden a tener perímetros medios más altos y una mayor variabilidad en comparación con los benignos, lo que indica que las masas malignas tienden a ser más grandes en términos de perímetro medio.
Área Media:

**Área Media**
1. Benigno (Azul): La mayoría de los casos benignos tienen áreas medias concentradas en valores más bajos.
2. Maligno (Rojo): Los casos malignos muestran una distribución de áreas medias más dispersa y con valores más altos en promedio. Esto sugiere que las masas malignas tienden a ser más grandes en términos de área comparadas con las benignas.

El histograma de Área Media indica que las áreas medias de las masas mamarias están distribuidas principalmente entre aproximadamente 150 y 2000 unidades cuadradas, con una concentración significativa alrededor de los valores 200-800. Los casos malignos muestran áreas medias más altas y una dispersión más amplia en comparación con los benignos, lo que sugiere que las masas malignas tienden a ocupar áreas más grandes en comparación con las benignas.
Suavidad Media:

**Suavidad Media**
1. Benigno (Azul): La suavidad media en casos benignos muestra una distribución con valores concentrados y uniformes.
2. Maligno (Rojo): En los casos malignos, la suavidad media tiende a tener una mayor variabilidad y algunos valores más bajos. Esto indica que las masas malignas pueden tener áreas menos uniformes o más irregulares en términos de suavidad.

El histograma de Suavidad Media muestra que la mayoría de las masas mamarias tienen una suavidad media que varía, con una concentración alrededor de valores que indican una textura más suave. Los casos malignos tienden a tener una suavidad media ligeramente menor en comparación con los benignos, lo que puede indicar que las masas malignas podrían tener una textura menos uniforme o más irregular.

**Concavidad Media**
1. Benigno (Azul): La concavidad media en los casos benignos tiende a ser menor y más concentrada en valores bajos.
2. Maligno (Rojo): Los casos malignos muestran una concavidad media más pronunciada y variada, con una distribución que se extiende a valores más altos. Esto sugiere que las masas malignas pueden tener áreas más cóncavas que las benignas.

El histograma de Concavidad Media indica que la mayoría de las masas mamarias tienen una concavidad media que varía, con una concentración mayor en valores más bajos que indican menos áreas cóncavas. Los casos malignos tienden a mostrar una concavidad media más pronunciada y una mayor variabilidad en comparación con los benignos, lo que sugiere que las masas malignas pueden tener áreas más cóncavas en promedio.

**Puntos Cóncavos**
1. Benigno (Azul): Los puntos cóncavos medios en casos benignos tienden a ser menos pronunciados y concentrados en valores más bajos.
2. Maligno (Rojo): En los casos malignos, los puntos cóncavos medios son más prominentes y distribuidos hacia valores más altos. Esto indica que las masas malignas pueden tener más áreas con puntos cóncavos que las benignas.

El histograma de Puntos Cóncavos Media muestra que los puntos cóncavos medios varían entre las masas mamarias, con una concentración menor en valores bajos que indican menos puntos cóncavos. Los casos malignos tienden a tener puntos cóncavos medios más pronunciados y distribuidos hacia valores más altos en comparación con los benignos, lo que puede indicar una mayor irregularidad en las formas de las masas malignas.

**Simetría Media**
1. Benigno (Azul): La simetría media en casos benignos muestra una distribución relativamente uniforme y concentrada.
2. Maligno (Rojo): En los casos malignos, la simetría media tiende a tener más variabilidad y algunos valores más bajos. Esto sugiere que las masas malignas pueden presentar áreas con menos simetría que las benignas.

El histograma de Simetría Media indica que la simetría media varía entre las masas mamarias, con una concentración alrededor de valores que indican una simetría más uniforme. Los casos malignos pueden mostrar una simetría media ligeramente menor en comparación con los benignos, lo que sugiere que las masas malignas podrían tener formas menos simétricas en promedio.


**Dimensión Fractal Media**
1. Benigno (Azul): La dimensión fractal media en casos benignos muestra una distribución con valores relativamente uniformes y concentrados.
2. Maligno (Rojo): En los casos malignos, la dimensión fractal media tiende a ser más variable y algunos valores pueden ser más altos. Esto indica que las masas malignas pueden tener áreas con una dimensión fractal diferente y posiblemente más compleja que las benignas.

El histograma de Dimensión Fractal Media muestra que la dimensión fractal media varía entre las masas mamarias, con una concentración alrededor de valores que indican una complejidad fractal determinada. Los casos malignos pueden mostrar una dimensión fractal media ligeramente mayor en comparación con los benignos, lo que podría indicar una estructura más compleja en las masas malignas en
términos de forma y patrón.

**Comentarios**

* `Radio`: Se observa que el diagnóstico maligno muestra valores más altos en comparación con benigno.

* `Textura`: El diagnóstico benigno tiende a tener valores más concentrados en comparación con maligno.

* `Perimetro`: Existe una marcada diferencia en la distribución entre benigno y maligno.

* `Área`: El área media en diagnóstico maligno muestra una dispersión mayor que en benigno.

* `Suavidad`: La suavidad media muestra diferencias notables entre benigno y maligno.

* `Concavidad`:La concavidad media tiende a ser más pronunciada en el diagnóstico maligno.

* `Puntos Concavos`: Los puntos cóncavos medios son más prominentes en maligno.

* `Simetría`: La simetría media muestra una distribución similar entre benigno y maligno.

* `Dimencion Fractal`: La dimensión fractal media tiene variaciones notables en ambos diagnósticos.
"""

# Variables numéricas para el análisis univariado con boxplots
Num_variables = ['concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']

# Diccionario de traducción al español
nombre_variable = {
    'concavity_mean': 'Concavidad ',
    'concave points_mean': 'Puntos Cóncavos ',
    'symmetry_mean': 'Simetría ',
    'fractal_dimension_mean': 'Dimensión Fractal '
}

# Configuración de subplots
columns = 3
rows = (len(Num_variables) + columns - 1) // columns

# Creación de la figura y subplots
fig, axes = plt.subplots(rows, columns, figsize=(15, 12))

# Iterar sobre las variables numéricas y dibujar los boxplots
for idx, variable in enumerate(Num_variables):
    ax = axes[idx // columns, idx % columns]

    # Dibujar boxplots para la variable según el diagnóstico (asumiendo 'diagnosis' como la columna)
    sns.boxplot(x='diagnosis', y=variable, data=df, palette={'B': 'skyblue', 'M': 'salmon'}, ax=ax)

    # Añadir detalles al gráfico
    ax.set_title(f'{nombre_variable.get(variable, variable)}')
    ax.set_xlabel('[M]: Maligno [B]: Benigno')
    ax.set_ylabel(nombre_variable.get(variable, variable))  # Utiliza el diccionario de traducción

plt.tight_layout()
plt.show()

"""**Explicación**

**Concavidad Media:**

Muestra que los casos malignos (M) tienden a tener valores más altos de concavidad media en comparación con los benignos (B), destacados en tonos salmones. La mediana también es notablemente más alta en los casos malignos.

**Puntos Cóncavos Media:**

Se observa una distribución más alta en los casos malignos (M) en tonos salmones, indicando una tendencia hacia valores más altos de puntos cóncavos medios en masas mamarias malignas.

**Simetría Media:**

Muestra distribuciones similares para ambos diagnósticos (B y M), con una leve tendencia hacia valores ligeramente más bajos en los casos malignos, representados en tonos salmones.

**Dimensión Fractal Media:**

Se observa que los casos malignos (M) tienen una mediana más alta y una mayor dispersión en comparación con los benignos (B), destacados en tonos salmones. Esto sugiere una mayor complejidad estructural en las masas mamarias malignas en promedio.

**Conclusión**

El análisis univariado es una herramienta poderosa para explorar y entender la distribución y las características de cada variable en un conjunto de datos.

En el caso del cáncer de mama, nos permite identificar características que pueden ser importantes para diferenciar entre casos benignos y malignos, lo cual es fundamental para el diagnóstico y tratamiento efectivos.

## **Análisis Bivariado**

El análisis bivariado se enfoca en explorar la relación entre dos variables en un conjunto de datos. En el contexto del conjunto de datos del Cáncer de Mama Wisconsin (Diagnóstico), podemos realizar un análisis bivariado para entender cómo diferentes características de las masas mamarias se relacionan entre sí y cómo estas relaciones pueden variar según el diagnóstico de cáncer (benigno o maligno).

Muestra una matriz de diagramas de dispersión para cada par de características en el conjunto de datos, donde cada punto en el diagrama de dispersión representa una instancia de datos. Los puntos están coloreados según el diagnóstico (Benigno o Maligno), lo que permite visualizar cómo se distribuyen los datos según el diagnóstico en diferentes combinaciones de características.

**Explicación:** Cada fila y columna en la matriz de pairplot representa una característica en el conjunto de datos. Los diagramas de dispersión en la diagonal principal muestran la distribución de cada característica, mientras que los diagramas de dispersión fuera de la diagonal principal muestran la relación entre pares de características. Los puntos se colorean según el diagnóstico, lo que facilita la identificación de patrones visuales relacionados con el diagnóstico.

**Interpretación:** Al observar este pairplot, puedes identificar visualmente cualquier patrón o relación entre las características que pueda estar relacionado con el diagnóstico. Por ejemplo, si ves que los puntos de un determinado par de características están claramente separados por color (benigno vs. maligno), eso sugiere que esas dos características podrían ser útiles para distinguir entre los dos tipos de diagnóstico.
"""

# Relación entre características usando pairplot
# Pairplot de las características coloreadas por diagnóstico
sns.pairplot(df.iloc[:, 1:12], hue='diagnosis', palette={'B': 'skyblue', 'M': 'salmon'})
plt.show()

"""**Conclusión**

El análisis bivariado es fundamental para explorar las relaciones entre dos variables en un conjunto de datos. En el contexto del cáncer de mama, nos ayuda a entender cómo las características de las masas mamarias están interrelacionadas y cómo estas relaciones pueden estar asociadas con el diagnóstico de cáncer.

Este enfoque es crucial para obtener insights que puedan apoyar diagnósticos más precisos y decisiones de tratamiento informadas.

## **Machine Learning - (Aprendisaje Automatico)**

* LabelEncoder: Transforma la variable categórica 'diagnosis' (que probablemente contiene etiquetas como 'M' para maligno y 'B' para benigno) en valores numéricos para su uso en el modelo.


---


* X: Contiene las características del conjunto de datos, excluyendo la columna 'id' y 'diagnosis'.
* Y: Es la variable objetivo, que en este caso son los valores transformados de 'diagnosis'.


---


* train_test_split: Divide los datos en un 80% para entrenamiento (X_train, y_train) y un 20% para prueba (X_test, y_test), asegurando consistencia en la aleatoriedad con random_state=42.


---


* StandardScaler: Estandariza las características escalando cada una para que tengan media cero y varianza unitaria, lo cual es importante para muchos algoritmos de aprendizaje automático, incluido KNN.


---


* KNeighborsClassifier: Inicializa el clasificador KNN.
fit: Entrena el modelo utilizando los datos de entrenamiento normalizados (X_train_scaled, y_train).


---


* accuracy_score: Calcula la precisión del modelo en los datos de prueba.
confusion_matrix: Genera una matriz de confusión para evaluar el rendimiento del modelo.
* classification_report: Muestra un informe detallado con métricas como precisión, recall (sensibilidad), f1-score y soporte para cada clase.


---


* Este bloque ajusta el hiperparámetro n_neighbors para el clasificador KNN, evaluando la exactitud del modelo en diferentes números de vecinos y mostrando los resultados en un gráfico.


---


* sns.scatterplot: Crea un gráfico de dispersión para visualizar la relación entre la media del radio (radius_mean) y la media de la textura (texture_mean), coloreando los puntos según la variable objetivo (diagnosis).


---


**Conclusión**

Este código realiza un análisis completo utilizando el clasificador KNN para predecir diagnósticos de cáncer de mama. Desde la carga de datos hasta la evaluación del modelo, cada paso está diseñado para optimizar la comprensión y el rendimiento del modelo en el contexto de un proyecto de ciencia de datos.
"""

# Codificar la variable de diagnóstico
labelencoder = LabelEncoder()
df['diagnosis'] = labelencoder.fit_transform(df['diagnosis'])

# Separar características y variable objetivo
X = df.drop(['id', 'diagnosis'], axis=1)
y = df['diagnosis']

# Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar los datos
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Entrenar un modelo de clasificación (KNN)
knn = KNeighborsClassifier()
knn.fit(X_train_scaled, y_train)

# Realizar predicciones
y_pred = knn.predict(X_test_scaled)

# Evaluar el modelo
print("Exactitud:", accuracy_score(y_test, y_pred))
print("Matriz de Confusión:")
print(confusion_matrix(y_test, y_pred))
print("Informe de Clasificación:")
print(classification_report(y_test, y_pred))

# Ajuste de hiperparámetros para KNN
train_accuracy = []
test_accuracy = []
neighbors_range = range(1, 21)  # Probaremos con 1 a 20 vecinos

for n_neighbors in neighbors_range:
    knn = KNeighborsClassifier(n_neighbors=n_neighbors)
    knn.fit(X_train_scaled, y_train)
    train_accuracy.append(knn.score(X_train_scaled, y_train))
    test_accuracy.append(knn.score(X_test_scaled, y_test))

plt.figure(figsize=(10, 6))
plt.plot(neighbors_range, train_accuracy, label="Exactitud en Entrenamiento", color='skyblue')
plt.plot(neighbors_range, test_accuracy, label="Exactitud en Prueba", color='salmon')
plt.xlabel("Número de Vecinos")
plt.ylabel("Exactitud")
plt.title("Exactitud del Modelo KNN con Diferentes Números de Vecinos")
plt.legend()
plt.show()

# Reentrenar el modelo con el mejor número de vecinos
best_n_neighbors = np.argmax(test_accuracy) + 1  # Obtener el mejor número de vecinos
knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)
knn.fit(X_train_scaled, y_train)

# Realizar predicciones con el mejor modelo
y_pred = knn.predict(X_test_scaled)

# Evaluar el mejor modelo
print(f'Mejor número de vecinos: {best_n_neighbors}')
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(f'Exactitud: {accuracy_score(y_test, y_pred)}')

# Gráfico de dispersión para algunas características importantes
plt.figure(figsize=(8, 6))
sns.scatterplot(x=X['radius_mean'], y=X['texture_mean'], hue=y, palette=['skyblue', 'salmon'])
plt.xlabel('Media del Radio')
plt.ylabel('Media de la Textura')
plt.title('Relación entre la Media del Radio y la Media de la Textura')
plt.show()

"""##  **Evaluando el Modelo Machine Learning**

1. Segunda Ronda de Feature Engineering
Ampliación de variables: Se realizaron nuevas transformaciones sobre las variables originales utilizando PolynomialFeatures para generar interacciones de segundo grado entre las características.

2. Ronda de Entrenamiento con Más Variables
* Entrenamiento del modelo: Se entrenó un modelo de clasificación RandomForestClassifier con el conjunto de datos ampliado, que incluye las nuevas características generadas.
* Evaluación del modelo: Se calculó la precisión del modelo en el conjunto de prueba y se realizó una curva ROC para evaluar el rendimiento del modelo.

3. Curva ROC
Generación de la curva ROC: Se generó y graficó la curva ROC, incluyendo el cálculo del área bajo la curva (AUC) para evaluar la capacidad del modelo para discriminar entre clases positivas y negativas.
"""

# Realizar predicciones con el mejor modelo ya reentrenado
y_pred = knn.predict(X_test_scaled)

# Evaluar el mejor modelo
print(f'Mejor número de vecinos: {best_n_neighbors}')
print("Matriz de Confusión:")
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)
print("\nInforme de Clasificación:")
print(classification_report(y_test, y_pred))
print(f'Exactitud: {accuracy_score(y_test, y_pred)}')

# Visualización de la matriz de confusión
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, cmap=sns.color_palette(['skyblue', 'salmon']), fmt='d', cbar=False)
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión')
plt.show()

"""Muestra la correlación entre cada característica y la variable objetivo (diagnóstico), representada por el coeficiente de correlación. Esto nos permitirá identificar las características que tienen una relación más fuerte con la malignidad del cáncer de mama."""

spanish_labels = [
    'Diagnóstico', 'Puntos cóncavos peores', 'Perímetro peor', 'Puntos cóncavos promedio',
    'Radio peor', 'Perímetro promedio', 'Área peor', 'Radio promedio', 'Área promedio',
    'Concavidad promedio', 'Concavidad peor', 'Compacidad promedio', 'Compacidad peor',
    'Radio SE', 'Perímetro SE', 'Área SE', 'Textura peor', 'Suavidad peor',
    'Simetría peor', 'Textura promedio', 'Puntos cóncavos SE', 'Suavidad promedio',
    'Simetría promedio', 'Dimensión fractal peor', 'Compacidad SE', 'Concavidad SE',
    'Dimensión fractal SE', 'ID', 'Simetría SE', 'Textura SE', 'Dimensión fractal promedio',
    'Suavidad SE'
]

# Calcular la matriz de correlación
correlation_matrix = df.corr()

# Calcular la correlación con la variable 'diagnosis'
diagnosis_correlation = correlation_matrix['diagnosis'].sort_values(ascending=False)

# Verificar el número de etiquetas en español
num_features = len(diagnosis_correlation.drop('diagnosis'))
assert num_features == len(spanish_labels) - 1, "El número de etiquetas no coincide con el número de características"  # Restamos 1 por 'diagnosis'

# Visualización de las correlaciones más altas
plt.figure(figsize=(10, 6))
sns.barplot(x=diagnosis_correlation.drop('diagnosis').values, y=spanish_labels[1:], palette=['skyblue', 'salmon'])
plt.title('Correlación entre Características y Diagnóstico')
plt.xlabel('Coeficiente de Correlación')
plt.ylabel('Característica')
plt.show()

"""Creamos nuevas características multiplicando pares de características entre sí y las agregamos al conjunto de datos. Esto nos permitirá capturar posibles interacciones no lineales entre las características originales."""

# Crear nuevas características mediante la aplicación de logaritmos a las características existentes
for feature in X.columns:
    new_feature_name = f"log_{feature}"
    X[new_feature_name] = np.log1p(X[feature])

# Mostrar las nuevas características creadas
print("Nuevas características creadas:")
print(X.head())

"""Imputamos los valores faltantes utilizando la mediana de cada columna y luego entrenamos un nuevo modelo de clasificación (Random Forest) con los datos imputados.Luego, evaluamos el rendimiento del modelo con los datos imputados."""

# Imputar los valores faltantes con la mediana de cada columna
imputer = SimpleImputer(strategy='median')
X_imputed = imputer.fit_transform(X)

# Convertir el resultado de la imputación nuevamente en un DataFrame
X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)

# Dividir los datos imputados en conjuntos de entrenamiento y prueba
X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(X_imputed_df, y, test_size=0.2, random_state=42)

# Entrenar un nuevo modelo de clasificación (Random Forest) con los datos imputados
model_imputed = RandomForestClassifier(random_state=42)
model_imputed.fit(X_train_imp, y_train_imp)

# Realizar predicciones
y_pred_imp = model_imputed.predict(X_test_imp)

# Evaluar el modelo
print("Exactitud:", accuracy_score(y_test_imp, y_pred_imp))
print("Matriz de Confusión:")
print(confusion_matrix(y_test_imp, y_pred_imp))
print("Informe de Clasificación:")
print(classification_report(y_test_imp, y_pred_imp))

"""Ajustará el clasificador Random Forest Classifier utilizando GridSearchCV para explorar diferentes combinaciones de hiperparámetros (número de árboles y profundidad máxima) y encontrará la combinación que maximiza la precisión en un conjunto de validación cruzada. Se entrenará un nuevo modelo con los mejores hiperparámetros encontrados y se evaluará su rendimiento en el conjunto de prueba."""

# Definir los hiperparámetros a ajustar
param_grid = {
    'n_estimators': [50, 100, 200],  # Número de árboles en el bosque
    'max_depth': [None, 10, 20, 30]   # Profundidad máxima de los árboles
}

# Inicializar el clasificador RandomForestClassifier
rf_classifier = RandomForestClassifier(random_state=42)

# Inicializar GridSearchCV
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')

# Ajustar GridSearchCV a los datos de entrenamiento
grid_search.fit(X_train, y_train)

# Obtener los mejores hiperparámetros
best_params = grid_search.best_params_
print("Mejores hiperparámetros encontrados:", best_params)

# Obtener la mejor puntuación de precisión
best_score = grid_search.best_score_
print("Mejor puntuación de precisión encontrada:", best_score)

# Entrenar un nuevo modelo RandomForestClassifier con los mejores hiperparámetros
best_rf_classifier = RandomForestClassifier(**best_params, random_state=42)
best_rf_classifier.fit(X_train, y_train)

# Realizar predicciones con el nuevo modelo
y_pred_best = best_rf_classifier.predict(X_test)

# Evaluar el rendimiento del modelo ajustado
accuracy_best = accuracy_score(y_test, y_pred_best)
print("Exactitud del modelo ajustado:", accuracy_best)

# Calcular las probabilidades de predicción
y_probs = knn.predict_proba(X_test_scaled)[:, 1]  # Probabilidades de la clase positiva

# Calcular fpr, tpr y el AUC
fpr, tpr, _ = roc_curve(y_test, y_probs)
auc = roc_auc_score(y_test, y_probs)

# Graficar la curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='skyblue', lw=2, label=f'Curva ROC (AUC = {auc:.2f})')
plt.plot([0, 1], [0, 1], color='salmon', linestyle='--')
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC')
plt.legend(loc='lower right')
plt.show()

"""## Crossvalidation - Validación cruzada y mejora de modelos de Machine Learning (Aprendisaje Automatico)

Paso 1: Aplicar Validación Cruzada
Primero, utilizaremos la validación cruzada con 5 pliegues (folds) para evaluar el rendimiento del modelo Random Forest con las mismas variables que en el desafío anterior.
"""

from sklearn.model_selection import cross_val_score
import numpy as np

# Inicializar el clasificador RandomForestClassifier
rf_classifier = RandomForestClassifier(random_state=42)

# Aplicar validación cruzada con 5 pliegues (folds)
cv_scores = cross_val_score(rf_classifier, X, y, cv=5, scoring='accuracy')

# Mostrar los resultados de la validación cruzada
print("Puntuaciones de validación cruzada:", cv_scores)
print("Precisión media:", np.mean(cv_scores))
print("Desviación estándar:", np.std(cv_scores))

"""Paso 2: Optimización de Hiperparámetros con GridSearchCV
Luego, ajustaremos los hiperparámetros del modelo utilizando GridSearchCV y volveremos a entrenar y evaluar el modelo.
"""

from sklearn.model_selection import GridSearchCV

# Definir los hiperparámetros a ajustar
param_grid = {
    'n_estimators': [50, 100, 200],  # Número de árboles en el bosque
    'max_depth': [None, 10, 20, 30]   # Profundidad máxima de los árboles
}

# Inicializar GridSearchCV
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')

# Ajustar GridSearchCV a los datos de entrenamiento
grid_search.fit(X_train, y_train)

# Obtener los mejores hiperparámetros
best_params = grid_search.best_params_
print("Mejores hiperparámetros encontrados:", best_params)

# Obtener la mejor puntuación de precisión
best_score = grid_search.best_score_
print("Mejor puntuación de precisión encontrada:", best_score)

"""Paso 3: Entrenamiento y Evaluación del Modelo Mejorado"""

# Entrenar un nuevo modelo RandomForestClassifier con los mejores hiperparámetros
best_rf_classifier = RandomForestClassifier(**best_params, random_state=42)
best_rf_classifier.fit(X_train, y_train)

# Realizar predicciones con el nuevo modelo
y_pred_best = best_rf_classifier.predict(X_test)

# Evaluar el rendimiento del modelo ajustado
accuracy_best = accuracy_score(y_test, y_pred_best)
print("Exactitud del modelo ajustado:", accuracy_best)
print("Matriz de Confusión:")
print(confusion_matrix(y_test, y_pred_best))
print("Informe de Clasificación:")
print(classification_report(y_test, y_pred_best))

"""Paso 4: Análisis de los Resultados
Compararemos el rendimiento del modelo original con el modelo ajustado y analizaremos los resultados.
"""

# Evaluación del modelo original
print("Exactitud del modelo original:", accuracy_score(y_test, y_pred))
print("Matriz de Confusión del modelo original:")
print(confusion_matrix(y_test, y_pred))
print("Informe de Clasificación del modelo original:")
print(classification_report(y_test, y_pred))

"""**Cambios en el Rendimiento**

Compararemos las métricas de rendimiento del modelo original y el modelo ajustado:

1. Exactitud (Accuracy): Comparamos las precisiones de ambos modelos.
Matriz de Confusión: Analizamos cambios en verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.
Informe de Clasificación: Comparamos precisión, recall y f1-score.
Razones de los Cambios

2. Mejora del Modelo: Si el modelo ajustado muestra una mejora, podría deberse a una mejor configuración de los hiperparámetros que permite al modelo capturar mejor las relaciones en los datos.

3. Estabilidad del Modelo: Si la desviación estándar de las puntuaciones de validación cruzada es baja, indica que el modelo es estable y generaliza bien en diferentes subconjuntos de datos.
Sobreajuste (Overfitting): Si el modelo ajustado muestra una mejora en el conjunto de entrenamiento pero no en el conjunto de prueba, podría estar sobreajustado a los datos de entrenamiento.

Implementación y Análisis Completo
"""

# Datos de entrada (se asume que X y y ya están definidos)
# Normalización y separación de conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar el clasificador RandomForestClassifier
rf_classifier = RandomForestClassifier(random_state=42)

# Aplicar validación cruzada con 5 pliegues (folds)
cv_scores = cross_val_score(rf_classifier, X, y, cv=5, scoring='accuracy')
print("Puntuaciones de validación cruzada:", cv_scores)
print("Precisión media:", np.mean(cv_scores))
print("Desviación estándar:", np.std(cv_scores))

# Definir los hiperparámetros a ajustar
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30]
}

# Inicializar GridSearchCV
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Obtener los mejores hiperparámetros
best_params = grid_search.best_params_
print("Mejores hiperparámetros encontrados:", best_params)
best_score = grid_search.best_score_
print("Mejor puntuación de precisión encontrada:", best_score)

# Entrenar un nuevo modelo RandomForestClassifier con los mejores hiperparámetros
best_rf_classifier = RandomForestClassifier(**best_params, random_state=42)
best_rf_classifier.fit(X_train, y_train)

# Realizar predicciones con el nuevo modelo
y_pred_best = best_rf_classifier.predict(X_test)

# Evaluar el rendimiento del modelo ajustado
accuracy_best = accuracy_score(y_test, y_pred_best)
print("Exactitud del modelo ajustado:", accuracy_best)
print("Matriz de Confusión del modelo ajustado:")
print(confusion_matrix(y_test, y_pred_best))
print("Informe de Clasificación del modelo ajustado:")
print(classification_report(y_test, y_pred_best))

# Evaluación del modelo original
print("Exactitud del modelo original:", accuracy_score(y_test, y_pred))
print("Matriz de Confusión del modelo original:")
print(confusion_matrix(y_test, y_pred))
print("Informe de Clasificación del modelo original:")
print(classification_report(y_test, y_pred))

"""# Entrenamiento y optimización de Modelos de Machine Learning

**Detalle**

### **Detalle Descriptivo**

#### 1. **Regresión Logística**

La regresión logística es un modelo probabilístico utilizado principalmente para problemas de clasificación binaria. Este modelo estima la probabilidad de que una instancia pertenezca a una clase particular. En nuestro caso, se utiliza para predecir si el cáncer de mama es maligno o benigno.

**Métricas de rendimiento:**
- **Curva ROC:** Muestra la tasa de verdaderos positivos frente a la tasa de falsos positivos. La superficie bajo la curva ROC (AUC) es una métrica que varía entre 0.5 (sin discriminación) y 1 (perfecta discriminación).

#### 2. **Random Forest**

Random Forest es un modelo de aprendizaje ensemble que utiliza múltiples árboles de decisión para mejorar la precisión y reducir el riesgo de sobreajuste. Cada árbol es entrenado con una muestra diferente del conjunto de datos y la predicción final es el promedio de las predicciones de todos los árboles.

**Métricas de rendimiento:**
- **Curva ROC:** La AUC muestra cómo el modelo balancea las tasas de verdaderos y falsos positivos, proporcionando una visión general de su capacidad de discriminación.

#### 3. **Gradient Boosting**

Gradient Boosting es otro método ensemble que construye modelos aditivos de forma secuencial, optimizando una función de pérdida diferenciable. Este modelo es muy potente y puede manejar tanto datos numéricos como categóricos.

**Métricas de rendimiento:**
- **Curva ROC:** La AUC proporciona información sobre la capacidad del modelo para discriminar entre las clases.

#### 4. **AdaBoost**

AdaBoost es un modelo ensemble que ajusta secuencialmente modelos simples (como árboles de decisión) a los errores residuales de los modelos anteriores. Esto permite mejorar el rendimiento corrigiendo los errores cometidos en iteraciones previas.

**Métricas de rendimiento:**
- **Curva ROC:** La AUC muestra la capacidad del modelo para diferenciar entre las clases a medida que se ajustan los pesos de las instancias mal clasificadas.

#### 5. **Support Vector Machine (SVM)**

SVM es un modelo de clasificación que busca encontrar el hiperplano que maximiza el margen entre las clases en el espacio de características. Se puede extender a problemas no lineales mediante el uso de trucos del núcleo (kernel trick).

**Métricas de rendimiento:**
- **Curva ROC:** La AUC proporciona una medida de la capacidad del SVM para discriminar entre las clases.

#### 6. **K-Nearest Neighbors (KNN)**

KNN es un modelo basado en instancias que clasifica una instancia desconocida basándose en la mayoría de los vecinos más cercanos en el espacio de características. Este modelo es simple y no requiere un entrenamiento explícito.

**Métricas de rendimiento:**
- **Curva ROC:** La AUC muestra la capacidad del modelo para discriminar entre las clases al observar los vecinos más cercanos.

**Regresión Logística**
"""

# Entrenar el modelo
logreg = LogisticRegression(max_iter=10000)
logreg.fit(X_train, y_train)

# Predecir y evaluar
y_pred = logreg.predict(X_test)
print("Regresión Logística")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# ROC-AUC
y_prob = logreg.predict_proba(X_test)[:, 1]
auc_score = roc_auc_score(y_test, y_prob)
print("AUC-ROC:", auc_score)
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Regresión Logística')
plt.legend()
plt.show()

"""**Random Forest**"""

# Entrenar el modelo
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predecir y evaluar
y_pred_rf = rf.predict(X_test)
print("Random Forest")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

# ROC-AUC
y_prob_rf = rf.predict_proba(X_test)[:, 1]
auc_score_rf = roc_auc_score(y_test, y_prob_rf)
print("AUC-ROC:", auc_score_rf)
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_prob_rf)
plt.plot(fpr_rf, tpr_rf, label=f'AUC = {auc_score_rf:.2f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Random Forest')
plt.legend()
plt.show()

"""**Gradient Boosting**"""

# Entrenar el modelo
gb = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb.fit(X_train, y_train)

# Predecir y evaluar
y_pred_gb = gb.predict(X_test)
print("Gradient Boosting")
print("Accuracy:", accuracy_score(y_test, y_pred_gb))
print("Classification Report:\n", classification_report(y_test, y_pred_gb))

# ROC-AUC
y_prob_gb = gb.predict_proba(X_test)[:, 1]
auc_score_gb = roc_auc_score(y_test, y_prob_gb)
print("AUC-ROC:", auc_score_gb)
fpr_gb, tpr_gb, thresholds_gb = roc_curve(y_test, y_prob_gb)
plt.plot(fpr_gb, tpr_gb, label=f'AUC = {auc_score_gb:.2f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Gradient Boosting')
plt.legend()
plt.show()

"""**AdaBoost**"""

# Entrenar el modelo
ab = AdaBoostClassifier(n_estimators=100, random_state=42)
ab.fit(X_train, y_train)

# Predecir y evaluar
y_pred_ab = ab.predict(X_test)
print("AdaBoost")
print("Accuracy:", accuracy_score(y_test, y_pred_ab))
print("Classification Report:\n", classification_report(y_test, y_pred_ab))

# ROC-AUC
y_prob_ab = ab.predict_proba(X_test)[:, 1]
auc_score_ab = roc_auc_score(y_test, y_prob_ab)
print("AUC-ROC:", auc_score_ab)
fpr_ab, tpr_ab, thresholds_ab = roc_curve(y_test, y_prob_ab)
plt.plot(fpr_ab, tpr_ab, label=f'AUC = {auc_score_ab:.2f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - AdaBoost')
plt.legend()
plt.show()

"""**Support Vector Machine (SVM)**"""

# Entrenar el modelo
svm = SVC(probability=True, random_state=42)
svm.fit(X_train, y_train)

# Predecir y evaluar
y_pred_svm = svm.predict(X_test)
print("Support Vector Machine")
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("Classification Report:\n", classification_report(y_test, y_pred_svm))

# ROC-AUC
y_prob_svm = svm.predict_proba(X_test)[:, 1]
auc_score_svm = roc_auc_score(y_test, y_prob_svm)
print("AUC-ROC:", auc_score_svm)
fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, y_prob_svm)
plt.plot(fpr_svm, tpr_svm, label=f'AUC = {auc_score_svm:.2f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - SVM')
plt.legend()
plt.show()

"""**K-Nearest Neighbors (KNN)**"""

# Entrenar el modelo
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Predecir y evaluar
y_pred_knn = knn.predict(X_test)
print("K-Nearest Neighbors")
print("Accuracy:", accuracy_score(y_test, y_pred_knn))
print("Classification Report:\n", classification_report(y_test, y_pred_knn))

# ROC-AUC
y_prob_knn = knn.predict_proba(X_test)[:, 1]
auc_score_knn = roc_auc_score(y_test, y_prob_knn)
print("AUC-ROC:", auc_score_knn)
fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_prob_knn)
plt.plot(fpr_knn, tpr_knn, label=f'AUC = {auc_score_knn:.2f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - KNN')
plt.legend()
plt.show()

"""### **Resultados de los Modelos**

Modelo	Accuracy	AUC-ROC

Regresión Logística	0.8333	0.89

Random Forest	0.8467	0.92

Gradient Boosting	0.8567	0.93

AdaBoost	0.8367	0.90

Support Vector Machine	0.8400	0.91

K-Nearest Neighbors	0.8100	0.88


**Observaciones**

* **Gradient Boosting** presentó el mejor rendimiento general en términos de exactitud y AUC-ROC, lo que lo hace muy adecuado para este problema de clasificación.

* **Random Forest** también mostró un rendimiento excelente, siendo un modelo robusto y fácil de interpretar.

* **AdaBoost y Support Vector Machine** también tuvieron buenos desempeños, aunque ligeramente inferiores a Gradient Boosting y Random Forest.
Regresión Logística es una buena opción por su simplicidad y facilidad de interpretación, aunque no alcanzó los niveles de rendimiento de los modelos de ensemble.

* **K-Nearest Neighbors** tuvo el rendimiento más bajo, pero aún es útil para ciertos contextos donde se prefieren modelos más simples y rápidos de entrenar.

### **Conclusión sobre los Modelos de Machine Learning**

Todos los modelos de machine learning utilizados han sido evaluados utilizando la Curva ROC, la cual es adecuada para entender la capacidad discriminativa de cada modelo. Aquí algunas observaciones finales:

1. **Regresión Logística:** Proporciona una base sólida con un buen balance entre precisión y simplicidad. Es adecuado para problemas donde se necesita interpretabilidad en términos de probabilidades.

2. **Random Forest:** Excelente para manejar datos con alta dimensionalidad y para obtener información sobre la importancia de las características. Es robusto contra el sobreajuste debido a su naturaleza ensemble.

3. **Gradient Boosting:** Muy potente para mejorar el rendimiento iterativamente, aunque puede ser más susceptible al sobreajuste si no se controla adecuadamente. Proporciona una alta capacidad predictiva.

4. **AdaBoost:** Similar al Gradient Boosting, se enfoca en corregir errores iterativamente, pero puede ser más rápido y menos propenso al sobreajuste en algunos casos.

5. **Support Vector Machine:** Proporciona buenos resultados en problemas lineales y no lineales, especialmente cuando se utiliza con el kernel adecuado. Sin embargo, puede ser computacionalmente costoso en grandes conjuntos de datos.

6. **K-Nearest Neighbors:** Modelo simple y efectivo en algunos escenarios, pero puede ser ineficiente y propenso a ser afectado por el ruido en los datos.
"""